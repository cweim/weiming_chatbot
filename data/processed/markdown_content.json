[
  {
    "id": "Chin Wei Ming’s Portfolio 28d2a0713ab449fa82d8851c163d4b1f",
    "source_file": "data/raw/notion_export/Chin Wei Ming’s Portfolio 28d2a0713ab449fa82d8851c163d4b1f.md",
    "type": "markdown",
    "title": "Chin Wei Ming’s Portfolio",
    "category": "portfolio_main",
    "raw_content": "# Chin Wei Ming’s Portfolio\n\n[Contact me!](Chin%20Wei%20Ming%E2%80%99s%20Portfolio%2028d2a0713ab449fa82d8851c163d4b1f/Contact%20me!%206f24bbf9cd1841828eca66536a06c65e.md)\n\n---\n\n## Short Bio\n\nFinal-year engineering student specialising in Design and Artificial Intelligence, with a minor in Computer Science and Digital Humanities. \n\n[Projects](Chin%20Wei%20Ming%E2%80%99s%20Portfolio%2028d2a0713ab449fa82d8851c163d4b1f/Projects%20aee4f34d22394d1690473e4917727405.csv)\n\n### Certifications\n\n---\n\n![Screenshot 2023-04-04 at 12.55.04 AM.png](Chin%20Wei%20Ming%E2%80%99s%20Portfolio%2028d2a0713ab449fa82d8851c163d4b1f/Screenshot_2023-04-04_at_12.55.04_AM.png)\n\n![Screenshot 2023-04-04 at 12.55.54 AM.png](Chin%20Wei%20Ming%E2%80%99s%20Portfolio%2028d2a0713ab449fa82d8851c163d4b1f/Screenshot_2023-04-04_at_12.55.54_AM.png)\n\n![Screenshot 2024-08-26 at 9.19.41 PM.png](Chin%20Wei%20Ming%E2%80%99s%20Portfolio%2028d2a0713ab449fa82d8851c163d4b1f/Screenshot_2024-08-26_at_9.19.41_PM.png)\n\n![Screenshot 2025-04-03 at 6.05.36 PM.png](Chin%20Wei%20Ming%E2%80%99s%20Portfolio%2028d2a0713ab449fa82d8851c163d4b1f/Screenshot_2025-04-03_at_6.05.36_PM.png)\n\n![Screenshot 2025-05-26 at 7.00.27 PM.png](Chin%20Wei%20Ming%E2%80%99s%20Portfolio%2028d2a0713ab449fa82d8851c163d4b1f/Screenshot_2025-05-26_at_7.00.27_PM.png)\n\n![Screenshot 2025-05-26 at 7.00.43 PM.png](Chin%20Wei%20Ming%E2%80%99s%20Portfolio%2028d2a0713ab449fa82d8851c163d4b1f/Screenshot_2025-05-26_at_7.00.43_PM.png)\n\n![Screenshot 2025-05-26 at 7.01.19 PM.png](Chin%20Wei%20Ming%E2%80%99s%20Portfolio%2028d2a0713ab449fa82d8851c163d4b1f/Screenshot_2025-05-26_at_7.01.19_PM.png)\n\n![Screenshot 2024-07-16 at 3.04.41 PM.png](Chin%20Wei%20Ming%E2%80%99s%20Portfolio%2028d2a0713ab449fa82d8851c163d4b1f/Screenshot_2024-07-16_at_3.04.41_PM.png)\n\n![Screenshot 2023-04-04 at 1.00.18 AM.png](Chin%20Wei%20Ming%E2%80%99s%20Portfolio%2028d2a0713ab449fa82d8851c163d4b1f/Screenshot_2023-04-04_at_1.00.18_AM.png)\n\n![Screenshot 2025-04-14 at 6.45.15 PM.png](Chin%20Wei%20Ming%E2%80%99s%20Portfolio%2028d2a0713ab449fa82d8851c163d4b1f/Screenshot_2025-04-14_at_6.45.15_PM.png)\n\n![Screenshot 2025-05-26 at 6.59.21 PM.png](Chin%20Wei%20Ming%E2%80%99s%20Portfolio%2028d2a0713ab449fa82d8851c163d4b1f/Screenshot_2025-05-26_at_6.59.21_PM.png)\n\n---",
    "cleaned_content": "# Chin Wei Ming’s Portfolio\n\n[Contact me!](Chin Wei Ming's Portfolio 28d2a0713ab449fa82d8851c163d4b1f/Contact me! 6f24bbf9cd1841828eca66536a06c65e.md)\n\n---\n\n## Short Bio\n\nFinal-year engineering student specialising in Design and Artificial Intelligence, with a minor in Computer Science and Digital Humanities. \n\n[Projects](Chin Wei Ming's Portfolio 28d2a0713ab449fa82d8851c163d4b1f/Projects aee4f34d22394d1690473e4917727405.csv)\n\n### Certifications\n\n---\n\n![Image: Screenshot 2023-04-04 at 12.55.04 AM.png]\n\n![Image: Screenshot 2023-04-04 at 12.55.54 AM.png]\n\n![Image: Screenshot 2024-08-26 at 9.19.41 PM.png]\n\n![Image: Screenshot 2025-04-03 at 6.05.36 PM.png]\n\n![Image: Screenshot 2025-05-26 at 7.00.27 PM.png]\n\n![Image: Screenshot 2025-05-26 at 7.00.43 PM.png]\n\n![Image: Screenshot 2025-05-26 at 7.01.19 PM.png]\n\n![Image: Screenshot 2024-07-16 at 3.04.41 PM.png]\n\n![Image: Screenshot 2023-04-04 at 1.00.18 AM.png]\n\n![Image: Screenshot 2025-04-14 at 6.45.15 PM.png]\n\n![Image: Screenshot 2025-05-26 at 6.59.21 PM.png]\n\n---",
    "plain_text": "Chin Wei Ming’s Portfolio Contact me! Short Bio Final-year engineering student specialising in Design and Artificial Intelligence, with a minor in Computer Science and Digital Humanities. Projects Certifications ![Image: Screenshot 2023-04-04 at 12.55.04 AM.png] ![Image: Screenshot 2023-04-04 at 12.55.54 AM.png] ![Image: Screenshot 2024-08-26 at 9.19.41 PM.png] ![Image: Screenshot 2025-04-03 at 6.05.36 PM.png] ![Image: Screenshot 2025-05-26 at 7.00.27 PM.png] ![Image: Screenshot 2025-05-26 at 7.00.43 PM.png] ![Image: Screenshot 2025-05-26 at 7.01.19 PM.png] ![Image: Screenshot 2024-07-16 at 3.04.41 PM.png] ![Image: Screenshot 2023-04-04 at 1.00.18 AM.png] ![Image: Screenshot 2025-04-14 at 6.45.15 PM.png] ![Image: Screenshot 2025-05-26 at 6.59.21 PM.png]",
    "sections": [
      {
        "title": "Chin Wei Ming’s Portfolio",
        "content": "\n[Contact me!](Chin Wei Ming's Portfolio 28d2a0713ab449fa82d8851c163d4b1f/Contact me! 6f24bbf9cd1841828eca66536a06c65e.md)\n\n---\n\n",
        "level": 1
      },
      {
        "title": "Short Bio",
        "content": "\nFinal-year engineering student specialising in Design and Artificial Intelligence, with a minor in Computer Science and Digital Humanities. \n\n[Projects](Chin Wei Ming's Portfolio 28d2a0713ab449fa82d8851c163d4b1f/Projects aee4f34d22394d1690473e4917727405.csv)\n\n",
        "level": 2
      },
      {
        "title": "Certifications",
        "content": "\n---\n\n![Image: Screenshot 2023-04-04 at 12.55.04 AM.png]\n\n![Image: Screenshot 2023-04-04 at 12.55.54 AM.png]\n\n![Image: Screenshot 2024-08-26 at 9.19.41 PM.png]\n\n![Image: Screenshot 2025-04-03 at 6.05.36 PM.png]\n\n![Image: Screenshot 2025-05-26 at 7.00.27 PM.png]\n\n![Image: Screenshot 2025-05-26 at 7.00.43 PM.png]\n\n![Image: Screenshot 2025-05-26 at 7.01.19 PM.png]\n\n![Image: Screenshot 2024-07-16 at 3.04.41 PM.png]\n\n![Image: Screenshot 2023-04-04 at 1.00.18 AM.png]\n\n![Image: Screenshot 2025-04-14 at 6.45.15 PM.png]\n\n![Image: Screenshot 2025-05-26 at 6.59.21 PM.png]\n\n---\n",
        "level": 3
      }
    ],
    "metadata": {
      "title": "Chin Wei Ming’s Portfolio",
      "category": "portfolio_main",
      "file_name": "Chin Wei Ming’s Portfolio 28d2a0713ab449fa82d8851c163d4b1f",
      "relative_path": "Chin Wei Ming’s Portfolio 28d2a0713ab449fa82d8851c163d4b1f.md",
      "last_modified": 1749024872.673125
    },
    "word_count": 94,
    "referenced_files": [
      {
        "name": "Screenshot 2023-04-04 at 12.55.04 AM.png",
        "path": "Chin%20Wei%20Ming%E2%80%99s%20Portfolio%2028d2a0713ab449fa82d8851c163d4b1f/Screenshot_2023-04-04_at_12.55.04_AM.png",
        "type": "png"
      },
      {
        "name": "Screenshot 2023-04-04 at 12.55.54 AM.png",
        "path": "Chin%20Wei%20Ming%E2%80%99s%20Portfolio%2028d2a0713ab449fa82d8851c163d4b1f/Screenshot_2023-04-04_at_12.55.54_AM.png",
        "type": "png"
      },
      {
        "name": "Screenshot 2024-08-26 at 9.19.41 PM.png",
        "path": "Chin%20Wei%20Ming%E2%80%99s%20Portfolio%2028d2a0713ab449fa82d8851c163d4b1f/Screenshot_2024-08-26_at_9.19.41_PM.png",
        "type": "png"
      },
      {
        "name": "Screenshot 2025-04-03 at 6.05.36 PM.png",
        "path": "Chin%20Wei%20Ming%E2%80%99s%20Portfolio%2028d2a0713ab449fa82d8851c163d4b1f/Screenshot_2025-04-03_at_6.05.36_PM.png",
        "type": "png"
      },
      {
        "name": "Screenshot 2025-05-26 at 7.00.27 PM.png",
        "path": "Chin%20Wei%20Ming%E2%80%99s%20Portfolio%2028d2a0713ab449fa82d8851c163d4b1f/Screenshot_2025-05-26_at_7.00.27_PM.png",
        "type": "png"
      },
      {
        "name": "Screenshot 2025-05-26 at 7.00.43 PM.png",
        "path": "Chin%20Wei%20Ming%E2%80%99s%20Portfolio%2028d2a0713ab449fa82d8851c163d4b1f/Screenshot_2025-05-26_at_7.00.43_PM.png",
        "type": "png"
      },
      {
        "name": "Screenshot 2025-05-26 at 7.01.19 PM.png",
        "path": "Chin%20Wei%20Ming%E2%80%99s%20Portfolio%2028d2a0713ab449fa82d8851c163d4b1f/Screenshot_2025-05-26_at_7.01.19_PM.png",
        "type": "png"
      },
      {
        "name": "Screenshot 2024-07-16 at 3.04.41 PM.png",
        "path": "Chin%20Wei%20Ming%E2%80%99s%20Portfolio%2028d2a0713ab449fa82d8851c163d4b1f/Screenshot_2024-07-16_at_3.04.41_PM.png",
        "type": "png"
      },
      {
        "name": "Screenshot 2023-04-04 at 1.00.18 AM.png",
        "path": "Chin%20Wei%20Ming%E2%80%99s%20Portfolio%2028d2a0713ab449fa82d8851c163d4b1f/Screenshot_2023-04-04_at_1.00.18_AM.png",
        "type": "png"
      },
      {
        "name": "Screenshot 2025-04-14 at 6.45.15 PM.png",
        "path": "Chin%20Wei%20Ming%E2%80%99s%20Portfolio%2028d2a0713ab449fa82d8851c163d4b1f/Screenshot_2025-04-14_at_6.45.15_PM.png",
        "type": "png"
      },
      {
        "name": "Screenshot 2025-05-26 at 6.59.21 PM.png",
        "path": "Chin%20Wei%20Ming%E2%80%99s%20Portfolio%2028d2a0713ab449fa82d8851c163d4b1f/Screenshot_2025-05-26_at_6.59.21_PM.png",
        "type": "png"
      }
    ]
  },
  {
    "id": "Chin Wei Ming’s Portfolio 28d2a0713ab449fa82d8851c163d4b1f_Contact me! 6f24bbf9cd1841828eca66536a06c65e",
    "source_file": "data/raw/notion_export/Chin Wei Ming’s Portfolio 28d2a0713ab449fa82d8851c163d4b1f/Contact me! 6f24bbf9cd1841828eca66536a06c65e.md",
    "type": "markdown",
    "title": "Contact me!",
    "category": "contact",
    "raw_content": "# Contact me!\n\n- [**Linked In](https://www.linkedin.com/in/chin-wei-ming-74b441246/)**\n- [**Email**](mailto:weiming1902@gmail.com?subject=ContactMe!&cc=weiming_chin@mymail.sutd.edu.sg)\n\nAlternatively, fill in this form for me to reach you!\n\n[https://chilipepper.io/form/medium-chopped-serrano-f95c9efa-2002-4808-a130-18c342d5b686](https://chilipepper.io/form/medium-chopped-serrano-f95c9efa-2002-4808-a130-18c342d5b686)",
    "cleaned_content": "# Contact me!\n\n- [**Linked In](https://www.linkedin.com/in/chin-wei-ming-74b441246/)**\n- [**Email**](mailto:weiming1902@gmail.com?subject=ContactMe!&cc=weiming_chin@mymail.sutd.edu.sg)\n\nAlternatively, fill in this form for me to reach you!\n\n[https://chilipepper.io/form/medium-chopped-serrano-f95c9efa-2002-4808-a130-18c342d5b686](https://chilipepper.io/form/medium-chopped-serrano-f95c9efa-2002-4808-a130-18c342d5b686)",
    "plain_text": "Contact me! **Linked In** Email Alternatively, fill in this form for me to reach you! https://chilipepper.io/form/medium-chopped-serrano-f95c9efa-2002-4808-a130-18c342d5b686",
    "sections": [
      {
        "title": "Contact me!",
        "content": "\n- [**Linked In](https://www.linkedin.com/in/chin-wei-ming-74b441246/)**\n- [**Email**](mailto:weiming1902@gmail.com?subject=ContactMe!&cc=weiming_chin@mymail.sutd.edu.sg)\n\nAlternatively, fill in this form for me to reach you!\n\n[https://chilipepper.io/form/medium-chopped-serrano-f95c9efa-2002-4808-a130-18c342d5b686](https://chilipepper.io/form/medium-chopped-serrano-f95c9efa-2002-4808-a130-18c342d5b686)\n",
        "level": 1
      }
    ],
    "metadata": {
      "title": "Contact me!",
      "category": "contact",
      "file_name": "Contact me! 6f24bbf9cd1841828eca66536a06c65e",
      "relative_path": "Chin Wei Ming’s Portfolio 28d2a0713ab449fa82d8851c163d4b1f/Contact me! 6f24bbf9cd1841828eca66536a06c65e.md",
      "last_modified": 1749024948.2534642
    },
    "word_count": 16,
    "referenced_files": []
  },
  {
    "id": "Chin Wei Ming’s Portfolio 28d2a0713ab449fa82d8851c163d4b1f_Projects aee4f34d22394d1690473e4917727405_Natural Language Processing for Stock Market Indic 092c857fce644727b25f0e5bdc450e4a",
    "source_file": "data/raw/notion_export/Chin Wei Ming’s Portfolio 28d2a0713ab449fa82d8851c163d4b1f/Projects aee4f34d22394d1690473e4917727405/Natural Language Processing for Stock Market Indic 092c857fce644727b25f0e5bdc450e4a.md",
    "type": "markdown",
    "title": "Natural Language Processing for Stock Market Indicator",
    "category": "project",
    "raw_content": "# Natural Language Processing for Stock Market Indicator\n\nTimeline: January 22, 2024 → April 29, 2024\nClient: SUTD\nMy Role: Data Analyst, Data Science, Machine Learning\nTools: Hugging Face Transformers, Pandas, Python\nDocument: ../team9.pdf\n\n## Overview\n\n**Objective:** Develop a reliable stock market indicator based on Twitter sentiment for stocks like AAPL, AMZN, GOOG, MSFT, and TSLA.\n\n![photo_2024-08-27 17.24.41.jpeg](Natural%20Language%20Processing%20for%20Stock%20Market%20Indic%20092c857fce644727b25f0e5bdc450e4a/photo_2024-08-27_17.24.41.jpeg)\n\n**Approach:**\n\n- **Data Collection:** Assembled a multivariable dataset combining historical stock market data with aggregated Twitter sentiment with pandas library.\n    \n    ![Screenshot 2024-08-27 at 5.26.55 PM.png](Natural%20Language%20Processing%20for%20Stock%20Market%20Indic%20092c857fce644727b25f0e5bdc450e4a/Screenshot_2024-08-27_at_5.26.55_PM.png)\n    \n    ![Screenshot 2024-08-27 at 5.31.15 PM.png](Natural%20Language%20Processing%20for%20Stock%20Market%20Indic%20092c857fce644727b25f0e5bdc450e4a/Screenshot_2024-08-27_at_5.31.15_PM.png)\n    \n- **Financial Sentiment Analysis:** Utilised the Hugging Face FinBERT model to analyse daily sentiment of tweets. Calculated a weighted average sentiment score, factoring in likes, retweets, and comments.\n- **Modelling:** Explored the Random Forest Classifier, performing 5-fold cross-validation and Grid Search CV to optimised parameters.\n    \n    ![Screenshot 2024-08-27 at 5.35.12 PM.png](Natural%20Language%20Processing%20for%20Stock%20Market%20Indic%20092c857fce644727b25f0e5bdc450e4a/Screenshot_2024-08-27_at_5.35.12_PM.png)\n    \n\n**Outcome:**\n\n- Achieved 85.2% accuracy in predicting daily stock market indicators.\n    \n    ![Screenshot 2024-08-27 at 5.33.52 PM.png](Natural%20Language%20Processing%20for%20Stock%20Market%20Indic%20092c857fce644727b25f0e5bdc450e4a/Screenshot_2024-08-27_at_5.33.52_PM.png)\n    \n- Demonstrated that Twitter sentiment significantly influences market movements.\n    \n    ![Screenshot 2024-08-27 at 5.33.21 PM.png](Natural%20Language%20Processing%20for%20Stock%20Market%20Indic%20092c857fce644727b25f0e5bdc450e4a/Screenshot_2024-08-27_at_5.33.21_PM.png)",
    "cleaned_content": "# Natural Language Processing for Stock Market Indicator\n\nTimeline: January 22, 2024 → April 29, 2024\nClient: SUTD\nMy Role: Data Analyst, Data Science, Machine Learning\nTools: Hugging Face Transformers, Pandas, Python\nDocument: ../team9.pdf\n\n## Overview\n\n**Objective:** Develop a reliable stock market indicator based on Twitter sentiment for stocks like AAPL, AMZN, GOOG, MSFT, and TSLA.\n\n![Image: photo_2024-08-27 17.24.41.jpeg]\n\n**Approach:**\n\n- **Data Collection:** Assembled a multivariable dataset combining historical stock market data with aggregated Twitter sentiment with pandas library.\n \n ![Image: Screenshot 2024-08-27 at 5.26.55 PM.png]\n \n ![Image: Screenshot 2024-08-27 at 5.31.15 PM.png]\n \n- **Financial Sentiment Analysis:** Utilised the Hugging Face FinBERT model to analyse daily sentiment of tweets. Calculated a weighted average sentiment score, factoring in likes, retweets, and comments.\n- **Modelling:** Explored the Random Forest Classifier, performing 5-fold cross-validation and Grid Search CV to optimised parameters.\n \n ![Image: Screenshot 2024-08-27 at 5.35.12 PM.png]\n\n**Outcome:**\n\n- Achieved 85.2% accuracy in predicting daily stock market indicators.\n \n ![Image: Screenshot 2024-08-27 at 5.33.52 PM.png]\n \n- Demonstrated that Twitter sentiment significantly influences market movements.\n \n ![Image: Screenshot 2024-08-27 at 5.33.21 PM.png]",
    "plain_text": "Natural Language Processing for Stock Market Indicator Timeline: January 22, 2024 → April 29, 2024 Client: SUTD My Role: Data Analyst, Data Science, Machine Learning Tools: Hugging Face Transformers, Pandas, Python Document: ../team9.pdf Overview Objective: Develop a reliable stock market indicator based on Twitter sentiment for stocks like AAPL, AMZN, GOOG, MSFT, and TSLA. ![Image: photo_2024-08-27 17.24.41.jpeg] Approach: Data Collection: Assembled a multivariable dataset combining historical stock market data with aggregated Twitter sentiment with pandas library. ![Image: Screenshot 2024-08-27 at 5.26.55 PM.png] ![Image: Screenshot 2024-08-27 at 5.31.15 PM.png] Financial Sentiment Analysis: Utilised the Hugging Face FinBERT model to analyse daily sentiment of tweets. Calculated a weighted average sentiment score, factoring in likes, retweets, and comments. Modelling: Explored the Random Forest Classifier, performing 5-fold cross-validation and Grid Search CV to optimised parameters. ![Image: Screenshot 2024-08-27 at 5.35.12 PM.png] Outcome: Achieved 85.2% accuracy in predicting daily stock market indicators. ![Image: Screenshot 2024-08-27 at 5.33.52 PM.png] Demonstrated that Twitter sentiment significantly influences market movements. ![Image: Screenshot 2024-08-27 at 5.33.21 PM.png]",
    "sections": [
      {
        "title": "Natural Language Processing for Stock Market Indicator",
        "content": "\nTimeline: January 22, 2024 → April 29, 2024\nClient: SUTD\nMy Role: Data Analyst, Data Science, Machine Learning\nTools: Hugging Face Transformers, Pandas, Python\nDocument: ../team9.pdf\n\n",
        "level": 1
      },
      {
        "title": "Overview",
        "content": "\n**Objective:** Develop a reliable stock market indicator based on Twitter sentiment for stocks like AAPL, AMZN, GOOG, MSFT, and TSLA.\n\n![Image: photo_2024-08-27 17.24.41.jpeg]\n\n**Approach:**\n\n- **Data Collection:** Assembled a multivariable dataset combining historical stock market data with aggregated Twitter sentiment with pandas library.\n \n ![Image: Screenshot 2024-08-27 at 5.26.55 PM.png]\n \n ![Image: Screenshot 2024-08-27 at 5.31.15 PM.png]\n \n- **Financial Sentiment Analysis:** Utilised the Hugging Face FinBERT model to analyse daily sentiment of tweets. Calculated a weighted average sentiment score, factoring in likes, retweets, and comments.\n- **Modelling:** Explored the Random Forest Classifier, performing 5-fold cross-validation and Grid Search CV to optimised parameters.\n \n ![Image: Screenshot 2024-08-27 at 5.35.12 PM.png]\n\n**Outcome:**\n\n- Achieved 85.2% accuracy in predicting daily stock market indicators.\n \n ![Image: Screenshot 2024-08-27 at 5.33.52 PM.png]\n \n- Demonstrated that Twitter sentiment significantly influences market movements.\n \n ![Image: Screenshot 2024-08-27 at 5.33.21 PM.png]\n",
        "level": 2
      }
    ],
    "metadata": {
      "title": "Natural Language Processing for Stock Market Indicator",
      "category": "project",
      "file_name": "Natural Language Processing for Stock Market Indic 092c857fce644727b25f0e5bdc450e4a",
      "relative_path": "Chin Wei Ming’s Portfolio 28d2a0713ab449fa82d8851c163d4b1f/Projects aee4f34d22394d1690473e4917727405/Natural Language Processing for Stock Market Indic 092c857fce644727b25f0e5bdc450e4a.md",
      "last_modified": 1749024949.031083
    },
    "word_count": 167,
    "referenced_files": [
      {
        "name": "photo_2024-08-27 17.24.41.jpeg",
        "path": "Natural%20Language%20Processing%20for%20Stock%20Market%20Indic%20092c857fce644727b25f0e5bdc450e4a/photo_2024-08-27_17.24.41.jpeg",
        "type": "jpeg"
      },
      {
        "name": "Screenshot 2024-08-27 at 5.26.55 PM.png",
        "path": "Natural%20Language%20Processing%20for%20Stock%20Market%20Indic%20092c857fce644727b25f0e5bdc450e4a/Screenshot_2024-08-27_at_5.26.55_PM.png",
        "type": "png"
      },
      {
        "name": "Screenshot 2024-08-27 at 5.31.15 PM.png",
        "path": "Natural%20Language%20Processing%20for%20Stock%20Market%20Indic%20092c857fce644727b25f0e5bdc450e4a/Screenshot_2024-08-27_at_5.31.15_PM.png",
        "type": "png"
      },
      {
        "name": "Screenshot 2024-08-27 at 5.35.12 PM.png",
        "path": "Natural%20Language%20Processing%20for%20Stock%20Market%20Indic%20092c857fce644727b25f0e5bdc450e4a/Screenshot_2024-08-27_at_5.35.12_PM.png",
        "type": "png"
      },
      {
        "name": "Screenshot 2024-08-27 at 5.33.52 PM.png",
        "path": "Natural%20Language%20Processing%20for%20Stock%20Market%20Indic%20092c857fce644727b25f0e5bdc450e4a/Screenshot_2024-08-27_at_5.33.52_PM.png",
        "type": "png"
      },
      {
        "name": "Screenshot 2024-08-27 at 5.33.21 PM.png",
        "path": "Natural%20Language%20Processing%20for%20Stock%20Market%20Indic%20092c857fce644727b25f0e5bdc450e4a/Screenshot_2024-08-27_at_5.33.21_PM.png",
        "type": "png"
      }
    ]
  },
  {
    "id": "Chin Wei Ming’s Portfolio 28d2a0713ab449fa82d8851c163d4b1f_Projects aee4f34d22394d1690473e4917727405_Deep Learning for Skin Lesion Classification 7da844f5134941638e3f3b1dc28b745c",
    "source_file": "data/raw/notion_export/Chin Wei Ming’s Portfolio 28d2a0713ab449fa82d8851c163d4b1f/Projects aee4f34d22394d1690473e4917727405/Deep Learning for Skin Lesion Classification 7da844f5134941638e3f3b1dc28b745c.md",
    "type": "markdown",
    "title": "Deep Learning for Skin Lesion Classification",
    "category": "project",
    "raw_content": "# Deep Learning for Skin Lesion Classification\n\nTimeline: January 22, 2024 → April 27, 2024\nClient: SUTD\nMy Role: Machine Learning Engineer\nTools: Convolutional Neural Network, Deep Learning, Image Processing, Machine Learning, Pytorch\nDocument: https://github.com/adikuma/Skin-Lesion-Classification/tree/main\n\n## Overview\n\n### **Deep Learning for Skin Cancer Detection**\n\n**Objective:** Develop an AI model capable of detecting skin cancer with accuracy comparable to a doctor's expertise.\n\n**Challenge:** With 99% of skin cancer cases being preventable if detected early, the goal was to create an automated and reliable system to identify the presence or absence of skin cancer in individuals using limited information.\n\n**Outcome:** The project focused on leveraging advanced AI and deep learning techniques to ensure accurate and early detection, potentially reducing the incidence of skin cancer through timely intervention.\n\n## Proposed Model Architecture\n\n---\n\n![Screenshot 2024-08-27 at 4.22.47 PM.png](Deep%20Learning%20for%20Skin%20Lesion%20Classification%207da844f5134941638e3f3b1dc28b745c/Screenshot_2024-08-27_at_4.22.47_PM.png)\n\n![Screenshot 2024-08-27 at 4.23.03 PM.png](Deep%20Learning%20for%20Skin%20Lesion%20Classification%207da844f5134941638e3f3b1dc28b745c/Screenshot_2024-08-27_at_4.23.03_PM.png)\n\n## Generative Adversarial Network\n\n---\n\n**Data Augmentation with GANs:** Explored Generative Adversarial Networks (GANs) to generate artificial images, increasing the training dataset. A separate neural network was trained to learn from real images and produce labeled artificial images.\n\n![photo_2024-08-27 16.24.46.jpeg](Deep%20Learning%20for%20Skin%20Lesion%20Classification%207da844f5134941638e3f3b1dc28b745c/photo_2024-08-27_16.24.46.jpeg)\n\n## Grad-CAM\n\n---\n\n**Model Explainability with GRAD-CAM:** Leveraged GRAD-CAM to visualise the areas the model focuses on when making predictions. This approach enhances reliability, helping users trust the prediction results by providing transparency.\n\n![Screenshot 2024-08-27 at 4.29.45 PM.png](Deep%20Learning%20for%20Skin%20Lesion%20Classification%207da844f5134941638e3f3b1dc28b745c/Screenshot_2024-08-27_at_4.29.45_PM.png)\n\n## Outcome\n\n---\n\nTrained on **40,000** images, the model achieved **72.43%** accuracy with the proposed architecture.\n\nThe project received full marks, recognising the extensive approach and innovative techniques employed by the team.\n\n[RPReplay_Final1724748207.mov](Deep%20Learning%20for%20Skin%20Lesion%20Classification%207da844f5134941638e3f3b1dc28b745c/RPReplay_Final1724748207.mov)",
    "cleaned_content": "# Deep Learning for Skin Lesion Classification\n\nTimeline: January 22, 2024 → April 27, 2024\nClient: SUTD\nMy Role: Machine Learning Engineer\nTools: Convolutional Neural Network, Deep Learning, Image Processing, Machine Learning, Pytorch\nDocument: https://github.com/adikuma/Skin-Lesion-Classification/tree/main\n\n## Overview\n\n### **Deep Learning for Skin Cancer Detection**\n\n**Objective:** Develop an AI model capable of detecting skin cancer with accuracy comparable to a doctor's expertise.\n\n**Challenge:** With 99% of skin cancer cases being preventable if detected early, the goal was to create an automated and reliable system to identify the presence or absence of skin cancer in individuals using limited information.\n\n**Outcome:** The project focused on leveraging advanced AI and deep learning techniques to ensure accurate and early detection, potentially reducing the incidence of skin cancer through timely intervention.\n\n## Proposed Model Architecture\n\n---\n\n![Image: Screenshot 2024-08-27 at 4.22.47 PM.png]\n\n![Image: Screenshot 2024-08-27 at 4.23.03 PM.png]\n\n## Generative Adversarial Network\n\n---\n\n**Data Augmentation with GANs:** Explored Generative Adversarial Networks (GANs) to generate artificial images, increasing the training dataset. A separate neural network was trained to learn from real images and produce labeled artificial images.\n\n![Image: photo_2024-08-27 16.24.46.jpeg]\n\n## Grad-CAM\n\n---\n\n**Model Explainability with GRAD-CAM:** Leveraged GRAD-CAM to visualise the areas the model focuses on when making predictions. This approach enhances reliability, helping users trust the prediction results by providing transparency.\n\n![Image: Screenshot 2024-08-27 at 4.29.45 PM.png]\n\n## Outcome\n\n---\n\nTrained on **40,000** images, the model achieved **72.43%** accuracy with the proposed architecture.\n\nThe project received full marks, recognising the extensive approach and innovative techniques employed by the team.\n\n[Image: RPReplay_Final1724748207.mov]",
    "plain_text": "Deep Learning for Skin Lesion Classification Timeline: January 22, 2024 → April 27, 2024 Client: SUTD My Role: Machine Learning Engineer Tools: Convolutional Neural Network, Deep Learning, Image Processing, Machine Learning, Pytorch Document: https://github.com/adikuma/Skin-Lesion-Classification/tree/main Overview Deep Learning for Skin Cancer Detection Objective: Develop an AI model capable of detecting skin cancer with accuracy comparable to a doctor's expertise. Challenge: With 99% of skin cancer cases being preventable if detected early, the goal was to create an automated and reliable system to identify the presence or absence of skin cancer in individuals using limited information. Outcome: The project focused on leveraging advanced AI and deep learning techniques to ensure accurate and early detection, potentially reducing the incidence of skin cancer through timely intervention. Proposed Model Architecture ![Image: Screenshot 2024-08-27 at 4.22.47 PM.png] ![Image: Screenshot 2024-08-27 at 4.23.03 PM.png] Generative Adversarial Network Data Augmentation with GANs: Explored Generative Adversarial Networks (GANs) to generate artificial images, increasing the training dataset. A separate neural network was trained to learn from real images and produce labeled artificial images. ![Image: photo_2024-08-27 16.24.46.jpeg] Grad-CAM Model Explainability with GRAD-CAM: Leveraged GRAD-CAM to visualise the areas the model focuses on when making predictions. This approach enhances reliability, helping users trust the prediction results by providing transparency. ![Image: Screenshot 2024-08-27 at 4.29.45 PM.png] Outcome Trained on 40,000 images, the model achieved 72.43% accuracy with the proposed architecture. The project received full marks, recognising the extensive approach and innovative techniques employed by the team. [Image: RPReplay_Final1724748207.mov]",
    "sections": [
      {
        "title": "Deep Learning for Skin Lesion Classification",
        "content": "\nTimeline: January 22, 2024 → April 27, 2024\nClient: SUTD\nMy Role: Machine Learning Engineer\nTools: Convolutional Neural Network, Deep Learning, Image Processing, Machine Learning, Pytorch\nDocument: https://github.com/adikuma/Skin-Lesion-Classification/tree/main\n\n",
        "level": 1
      },
      {
        "title": "**Deep Learning for Skin Cancer Detection**",
        "content": "\n**Objective:** Develop an AI model capable of detecting skin cancer with accuracy comparable to a doctor's expertise.\n\n**Challenge:** With 99% of skin cancer cases being preventable if detected early, the goal was to create an automated and reliable system to identify the presence or absence of skin cancer in individuals using limited information.\n\n**Outcome:** The project focused on leveraging advanced AI and deep learning techniques to ensure accurate and early detection, potentially reducing the incidence of skin cancer through timely intervention.\n\n",
        "level": 3
      },
      {
        "title": "Proposed Model Architecture",
        "content": "\n---\n\n![Image: Screenshot 2024-08-27 at 4.22.47 PM.png]\n\n![Image: Screenshot 2024-08-27 at 4.23.03 PM.png]\n\n",
        "level": 2
      },
      {
        "title": "Generative Adversarial Network",
        "content": "\n---\n\n**Data Augmentation with GANs:** Explored Generative Adversarial Networks (GANs) to generate artificial images, increasing the training dataset. A separate neural network was trained to learn from real images and produce labeled artificial images.\n\n![Image: photo_2024-08-27 16.24.46.jpeg]\n\n",
        "level": 2
      },
      {
        "title": "Grad-CAM",
        "content": "\n---\n\n**Model Explainability with GRAD-CAM:** Leveraged GRAD-CAM to visualise the areas the model focuses on when making predictions. This approach enhances reliability, helping users trust the prediction results by providing transparency.\n\n![Image: Screenshot 2024-08-27 at 4.29.45 PM.png]\n\n",
        "level": 2
      },
      {
        "title": "Outcome",
        "content": "\n---\n\nTrained on **40,000** images, the model achieved **72.43%** accuracy with the proposed architecture.\n\nThe project received full marks, recognising the extensive approach and innovative techniques employed by the team.\n\n[Image: RPReplay_Final1724748207.mov]\n",
        "level": 2
      }
    ],
    "metadata": {
      "title": "Deep Learning for Skin Lesion Classification",
      "category": "project",
      "file_name": "Deep Learning for Skin Lesion Classification 7da844f5134941638e3f3b1dc28b745c",
      "relative_path": "Chin Wei Ming’s Portfolio 28d2a0713ab449fa82d8851c163d4b1f/Projects aee4f34d22394d1690473e4917727405/Deep Learning for Skin Lesion Classification 7da844f5134941638e3f3b1dc28b745c.md",
      "last_modified": 1749024948.7848742
    },
    "word_count": 245,
    "referenced_files": [
      {
        "name": "Screenshot 2024-08-27 at 4.22.47 PM.png",
        "path": "Deep%20Learning%20for%20Skin%20Lesion%20Classification%207da844f5134941638e3f3b1dc28b745c/Screenshot_2024-08-27_at_4.22.47_PM.png",
        "type": "png"
      },
      {
        "name": "Screenshot 2024-08-27 at 4.23.03 PM.png",
        "path": "Deep%20Learning%20for%20Skin%20Lesion%20Classification%207da844f5134941638e3f3b1dc28b745c/Screenshot_2024-08-27_at_4.23.03_PM.png",
        "type": "png"
      },
      {
        "name": "photo_2024-08-27 16.24.46.jpeg",
        "path": "Deep%20Learning%20for%20Skin%20Lesion%20Classification%207da844f5134941638e3f3b1dc28b745c/photo_2024-08-27_16.24.46.jpeg",
        "type": "jpeg"
      },
      {
        "name": "Screenshot 2024-08-27 at 4.29.45 PM.png",
        "path": "Deep%20Learning%20for%20Skin%20Lesion%20Classification%207da844f5134941638e3f3b1dc28b745c/Screenshot_2024-08-27_at_4.29.45_PM.png",
        "type": "png"
      },
      {
        "name": "RPReplay_Final1724748207.mov",
        "path": "Deep%20Learning%20for%20Skin%20Lesion%20Classification%207da844f5134941638e3f3b1dc28b745c/RPReplay_Final1724748207.mov",
        "type": "mov"
      }
    ]
  },
  {
    "id": "Chin Wei Ming’s Portfolio 28d2a0713ab449fa82d8851c163d4b1f_Projects aee4f34d22394d1690473e4917727405_Central Provident Fund (CPF) Board Manpower Optimi b2d449e2d8584adbaf3efcfdcede232c",
    "source_file": "data/raw/notion_export/Chin Wei Ming’s Portfolio 28d2a0713ab449fa82d8851c163d4b1f/Projects aee4f34d22394d1690473e4917727405/Central Provident Fund (CPF) Board Manpower Optimi b2d449e2d8584adbaf3efcfdcede232c.md",
    "type": "markdown",
    "title": "Central Provident Fund (CPF) Board Manpower Optimisation System",
    "category": "project",
    "raw_content": "# Central Provident Fund (CPF) Board Manpower Optimisation System\n\nTimeline: January 21, 2024 → April 27, 2024\nClient: Central Provident Fund Board\nMy Role: Solution Engineer\nTools: Agent Based Simulation, Discrete Event Simulation, Figma, Javascript, Pandas library, Python, R Studio, Systems Dynamics\nDocument: ../Final_Presentation.pdf\n\n### **Manpower Optimisation System for CPF**\n\n**Objective:** Develop a system to optimise manpower allocation for the Central Provident Fund (CPF) Board, addressing the challenge of accurately forecasting enquiry volumes during peak periods.\n\n**Challenge:** CPF faced operational inefficiencies due to inaccurate forecasting of incoming enquiry volumes, leading to over/understaffing and unnecessary operational costs.\n\n**Approach:**\n\n- **Stakeholder Engagement:** Conducted site visits and interviews with key stakeholders to understand pain points.\n- **Design Prototyping:** Iterated multiple design prototypes with the client, refining the solution to meet their needs.\n- **Manpower Optimisation:** Designed a system to address forecasting challenges and optimise staff allocation.\n\n**Role:**\n\n- Led the design of solutions for each identified pain point, creating Figma prototypes.\n- Developed a mathematical model to effectively forecast enquiry demand.\n- Researched and selected a suitable simulation system to support the project’s objectives.\n\n## Systems Dynamics Simulation System\n\n---\n\n![Screenshot 2024-08-27 at 5.48.21 PM.png](Central%20Provident%20Fund%20(CPF)%20Board%20Manpower%20Optimi%20b2d449e2d8584adbaf3efcfdcede232c/Screenshot_2024-08-27_at_5.48.21_PM.png)\n\n## Exploration of other Simulation System\n\n---\n\n- Agent Based Simulation\n    \n    ![Screenshot 2024-08-28 at 1.07.55 PM.png](Central%20Provident%20Fund%20(CPF)%20Board%20Manpower%20Optimi%20b2d449e2d8584adbaf3efcfdcede232c/Screenshot_2024-08-28_at_1.07.55_PM.png)\n    \n- Discrete Event Simulation\n    \n    ![Screenshot 2024-08-28 at 1.08.12 PM.png](Central%20Provident%20Fund%20(CPF)%20Board%20Manpower%20Optimi%20b2d449e2d8584adbaf3efcfdcede232c/Screenshot_2024-08-28_at_1.08.12_PM.png)\n    \n\n## Solution Design Iterations\n\n---\n\n- Iteration 1\n    \n    ![Screenshot 2024-08-28 at 1.13.50 PM.png](Central%20Provident%20Fund%20(CPF)%20Board%20Manpower%20Optimi%20b2d449e2d8584adbaf3efcfdcede232c/Screenshot_2024-08-28_at_1.13.50_PM.png)\n    \n- Iteration 2\n    \n    ![Screenshot 2024-08-28 at 1.12.58 PM.png](Central%20Provident%20Fund%20(CPF)%20Board%20Manpower%20Optimi%20b2d449e2d8584adbaf3efcfdcede232c/Screenshot_2024-08-28_at_1.12.58_PM.png)\n    \n- Final Solution\n    \n    [Screen Recording 2024-08-28 at 2.30.00 PM.mov](Central%20Provident%20Fund%20(CPF)%20Board%20Manpower%20Optimi%20b2d449e2d8584adbaf3efcfdcede232c/Screen_Recording_2024-08-28_at_2.30.00_PM.mov)\n    \n\n## Simulating Open Balance\n\n---\n\n- **Forecasting New Incoming Cases** - With historical data of daily new cases, our machine learning regression model is able to forecast the number of new cases coming in.\n    \n    ![Screenshot 2024-08-28 at 2.23.49 PM.png](Central%20Provident%20Fund%20(CPF)%20Board%20Manpower%20Optimi%20b2d449e2d8584adbaf3efcfdcede232c/Screenshot_2024-08-28_at_2.23.49_PM.png)\n    \n- **Simulating Total Closed Case** - With historical data of daily productivity rate for each employee type, we are able to make an accurate prediction of number of daily case closure rate.\n    \n    ![Screenshot 2024-08-28 at 2.27.12 PM.png](Central%20Provident%20Fund%20(CPF)%20Board%20Manpower%20Optimi%20b2d449e2d8584adbaf3efcfdcede232c/Screenshot_2024-08-28_at_2.27.12_PM.png)\n    \n- **Simulating Open Balance** - With the above 2 data, we simply simulate open balance of cases for the upcoming week by finding the difference between both!\n    \n    ![Screenshot 2024-08-28 at 2.28.32 PM.png](Central%20Provident%20Fund%20(CPF)%20Board%20Manpower%20Optimi%20b2d449e2d8584adbaf3efcfdcede232c/Screenshot_2024-08-28_at_2.28.32_PM.png)\n    \n\n## Data-driven Manpower Allocation\n\n---\n\n- Using the data, we developed a data-driven approach to guide supervisors on the number of cases each employee type should close to meet their weekly targets.\n    \n    ![Screenshot 2024-08-28 at 2.34.02 PM.png](Central%20Provident%20Fund%20(CPF)%20Board%20Manpower%20Optimi%20b2d449e2d8584adbaf3efcfdcede232c/Screenshot_2024-08-28_at_2.34.02_PM.png)\n    \n\n## Outcome\n\n---\n\n**ed**\n\n**Data-driven approach** to determine daily staffing levels, **improving operational efficiency.**",
    "cleaned_content": "# Central Provident Fund (CPF) Board Manpower Optimisation System\n\nTimeline: January 21, 2024 → April 27, 2024\nClient: Central Provident Fund Board\nMy Role: Solution Engineer\nTools: Agent Based Simulation, Discrete Event Simulation, Figma, Javascript, Pandas library, Python, R Studio, Systems Dynamics\nDocument: ../Final_Presentation.pdf\n\n### **Manpower Optimisation System for CPF**\n\n**Objective:** Develop a system to optimise manpower allocation for the Central Provident Fund (CPF) Board, addressing the challenge of accurately forecasting enquiry volumes during peak periods.\n\n**Challenge:** CPF faced operational inefficiencies due to inaccurate forecasting of incoming enquiry volumes, leading to over/understaffing and unnecessary operational costs.\n\n**Approach:**\n\n- **Stakeholder Engagement:** Conducted site visits and interviews with key stakeholders to understand pain points.\n- **Design Prototyping:** Iterated multiple design prototypes with the client, refining the solution to meet their needs.\n- **Manpower Optimisation:** Designed a system to address forecasting challenges and optimise staff allocation.\n\n**Role:**\n\n- Led the design of solutions for each identified pain point, creating Figma prototypes.\n- Developed a mathematical model to effectively forecast enquiry demand.\n- Researched and selected a suitable simulation system to support the project’s objectives.\n\n## Systems Dynamics Simulation System\n\n---\n\n![Screenshot 2024-08-27 at 5.48.21 PM.png](Central Provident Fund (CPF) Board Manpower Optimi b2d449e2d8584adbaf3efcfdcede232c/Screenshot_2024-08-27_at_5.48.21_PM.png)\n\n## Exploration of other Simulation System\n\n---\n\n- Agent Based Simulation\n \n ![Screenshot 2024-08-28 at 1.07.55 PM.png](Central Provident Fund (CPF) Board Manpower Optimi b2d449e2d8584adbaf3efcfdcede232c/Screenshot_2024-08-28_at_1.07.55_PM.png)\n \n- Discrete Event Simulation\n \n ![Screenshot 2024-08-28 at 1.08.12 PM.png](Central Provident Fund (CPF) Board Manpower Optimi b2d449e2d8584adbaf3efcfdcede232c/Screenshot_2024-08-28_at_1.08.12_PM.png)\n\n## Solution Design Iterations\n\n---\n\n- Iteration 1\n \n ![Screenshot 2024-08-28 at 1.13.50 PM.png](Central Provident Fund (CPF) Board Manpower Optimi b2d449e2d8584adbaf3efcfdcede232c/Screenshot_2024-08-28_at_1.13.50_PM.png)\n \n- Iteration 2\n \n ![Screenshot 2024-08-28 at 1.12.58 PM.png](Central Provident Fund (CPF) Board Manpower Optimi b2d449e2d8584adbaf3efcfdcede232c/Screenshot_2024-08-28_at_1.12.58_PM.png)\n \n- Final Solution\n \n [Screen Recording 2024-08-28 at 2.30.00 PM.mov](Central Provident Fund (CPF) Board Manpower Optimi b2d449e2d8584adbaf3efcfdcede232c/Screen_Recording_2024-08-28_at_2.30.00_PM.mov)\n\n## Simulating Open Balance\n\n---\n\n- **Forecasting New Incoming Cases** - With historical data of daily new cases, our machine learning regression model is able to forecast the number of new cases coming in.\n \n ![Screenshot 2024-08-28 at 2.23.49 PM.png](Central Provident Fund (CPF) Board Manpower Optimi b2d449e2d8584adbaf3efcfdcede232c/Screenshot_2024-08-28_at_2.23.49_PM.png)\n \n- **Simulating Total Closed Case** - With historical data of daily productivity rate for each employee type, we are able to make an accurate prediction of number of daily case closure rate.\n \n ![Screenshot 2024-08-28 at 2.27.12 PM.png](Central Provident Fund (CPF) Board Manpower Optimi b2d449e2d8584adbaf3efcfdcede232c/Screenshot_2024-08-28_at_2.27.12_PM.png)\n \n- **Simulating Open Balance** - With the above 2 data, we simply simulate open balance of cases for the upcoming week by finding the difference between both!\n \n ![Screenshot 2024-08-28 at 2.28.32 PM.png](Central Provident Fund (CPF) Board Manpower Optimi b2d449e2d8584adbaf3efcfdcede232c/Screenshot_2024-08-28_at_2.28.32_PM.png)\n\n## Data-driven Manpower Allocation\n\n---\n\n- Using the data, we developed a data-driven approach to guide supervisors on the number of cases each employee type should close to meet their weekly targets.\n \n ![Screenshot 2024-08-28 at 2.34.02 PM.png](Central Provident Fund (CPF) Board Manpower Optimi b2d449e2d8584adbaf3efcfdcede232c/Screenshot_2024-08-28_at_2.34.02_PM.png)\n\n## Outcome\n\n---\n\n**ed**\n\n**Data-driven approach** to determine daily staffing levels, **improving operational efficiency.**",
    "plain_text": "Central Provident Fund (CPF) Board Manpower Optimisation System Timeline: January 21, 2024 → April 27, 2024 Client: Central Provident Fund Board My Role: Solution Engineer Tools: Agent Based Simulation, Discrete Event Simulation, Figma, Javascript, Pandas library, Python, R Studio, Systems Dynamics Document: ../Final_Presentation.pdf Manpower Optimisation System for CPF Objective: Develop a system to optimise manpower allocation for the Central Provident Fund (CPF) Board, addressing the challenge of accurately forecasting enquiry volumes during peak periods. Challenge: CPF faced operational inefficiencies due to inaccurate forecasting of incoming enquiry volumes, leading to over/understaffing and unnecessary operational costs. Approach: Stakeholder Engagement: Conducted site visits and interviews with key stakeholders to understand pain points. Design Prototyping: Iterated multiple design prototypes with the client, refining the solution to meet their needs. Manpower Optimisation: Designed a system to address forecasting challenges and optimise staff allocation. Role: Led the design of solutions for each identified pain point, creating Figma prototypes. Developed a mathematical model to effectively forecast enquiry demand. Researched and selected a suitable simulation system to support the project’s objectives. Systems Dynamics Simulation System Exploration of other Simulation System Agent Based Simulation Discrete Event Simulation Solution Design Iterations Iteration 1 Iteration 2 Final Solution Screen Recording 2024-08-28 at 2.30.00 PM.mov Simulating Open Balance Forecasting New Incoming Cases - With historical data of daily new cases, our machine learning regression model is able to forecast the number of new cases coming in. Simulating Total Closed Case - With historical data of daily productivity rate for each employee type, we are able to make an accurate prediction of number of daily case closure rate. Simulating Open Balance - With the above 2 data, we simply simulate open balance of cases for the upcoming week by finding the difference between both! Data-driven Manpower Allocation Using the data, we developed a data-driven approach to guide supervisors on the number of cases each employee type should close to meet their weekly targets. Outcome ed Data-driven approach to determine daily staffing levels, improving operational efficiency.",
    "sections": [
      {
        "title": "Central Provident Fund (CPF) Board Manpower Optimisation System",
        "content": "\nTimeline: January 21, 2024 → April 27, 2024\nClient: Central Provident Fund Board\nMy Role: Solution Engineer\nTools: Agent Based Simulation, Discrete Event Simulation, Figma, Javascript, Pandas library, Python, R Studio, Systems Dynamics\nDocument: ../Final_Presentation.pdf\n\n",
        "level": 1
      },
      {
        "title": "**Manpower Optimisation System for CPF**",
        "content": "\n**Objective:** Develop a system to optimise manpower allocation for the Central Provident Fund (CPF) Board, addressing the challenge of accurately forecasting enquiry volumes during peak periods.\n\n**Challenge:** CPF faced operational inefficiencies due to inaccurate forecasting of incoming enquiry volumes, leading to over/understaffing and unnecessary operational costs.\n\n**Approach:**\n\n- **Stakeholder Engagement:** Conducted site visits and interviews with key stakeholders to understand pain points.\n- **Design Prototyping:** Iterated multiple design prototypes with the client, refining the solution to meet their needs.\n- **Manpower Optimisation:** Designed a system to address forecasting challenges and optimise staff allocation.\n\n**Role:**\n\n- Led the design of solutions for each identified pain point, creating Figma prototypes.\n- Developed a mathematical model to effectively forecast enquiry demand.\n- Researched and selected a suitable simulation system to support the project’s objectives.\n\n",
        "level": 3
      },
      {
        "title": "Systems Dynamics Simulation System",
        "content": "\n---\n\n![Screenshot 2024-08-27 at 5.48.21 PM.png](Central Provident Fund (CPF) Board Manpower Optimi b2d449e2d8584adbaf3efcfdcede232c/Screenshot_2024-08-27_at_5.48.21_PM.png)\n\n",
        "level": 2
      },
      {
        "title": "Exploration of other Simulation System",
        "content": "\n---\n\n- Agent Based Simulation\n \n ![Screenshot 2024-08-28 at 1.07.55 PM.png](Central Provident Fund (CPF) Board Manpower Optimi b2d449e2d8584adbaf3efcfdcede232c/Screenshot_2024-08-28_at_1.07.55_PM.png)\n \n- Discrete Event Simulation\n \n ![Screenshot 2024-08-28 at 1.08.12 PM.png](Central Provident Fund (CPF) Board Manpower Optimi b2d449e2d8584adbaf3efcfdcede232c/Screenshot_2024-08-28_at_1.08.12_PM.png)\n\n",
        "level": 2
      },
      {
        "title": "Solution Design Iterations",
        "content": "\n---\n\n- Iteration 1\n \n ![Screenshot 2024-08-28 at 1.13.50 PM.png](Central Provident Fund (CPF) Board Manpower Optimi b2d449e2d8584adbaf3efcfdcede232c/Screenshot_2024-08-28_at_1.13.50_PM.png)\n \n- Iteration 2\n \n ![Screenshot 2024-08-28 at 1.12.58 PM.png](Central Provident Fund (CPF) Board Manpower Optimi b2d449e2d8584adbaf3efcfdcede232c/Screenshot_2024-08-28_at_1.12.58_PM.png)\n \n- Final Solution\n \n [Screen Recording 2024-08-28 at 2.30.00 PM.mov](Central Provident Fund (CPF) Board Manpower Optimi b2d449e2d8584adbaf3efcfdcede232c/Screen_Recording_2024-08-28_at_2.30.00_PM.mov)\n\n",
        "level": 2
      },
      {
        "title": "Simulating Open Balance",
        "content": "\n---\n\n- **Forecasting New Incoming Cases** - With historical data of daily new cases, our machine learning regression model is able to forecast the number of new cases coming in.\n \n ![Screenshot 2024-08-28 at 2.23.49 PM.png](Central Provident Fund (CPF) Board Manpower Optimi b2d449e2d8584adbaf3efcfdcede232c/Screenshot_2024-08-28_at_2.23.49_PM.png)\n \n- **Simulating Total Closed Case** - With historical data of daily productivity rate for each employee type, we are able to make an accurate prediction of number of daily case closure rate.\n \n ![Screenshot 2024-08-28 at 2.27.12 PM.png](Central Provident Fund (CPF) Board Manpower Optimi b2d449e2d8584adbaf3efcfdcede232c/Screenshot_2024-08-28_at_2.27.12_PM.png)\n \n- **Simulating Open Balance** - With the above 2 data, we simply simulate open balance of cases for the upcoming week by finding the difference between both!\n \n ![Screenshot 2024-08-28 at 2.28.32 PM.png](Central Provident Fund (CPF) Board Manpower Optimi b2d449e2d8584adbaf3efcfdcede232c/Screenshot_2024-08-28_at_2.28.32_PM.png)\n\n",
        "level": 2
      },
      {
        "title": "Data-driven Manpower Allocation",
        "content": "\n---\n\n- Using the data, we developed a data-driven approach to guide supervisors on the number of cases each employee type should close to meet their weekly targets.\n \n ![Screenshot 2024-08-28 at 2.34.02 PM.png](Central Provident Fund (CPF) Board Manpower Optimi b2d449e2d8584adbaf3efcfdcede232c/Screenshot_2024-08-28_at_2.34.02_PM.png)\n\n",
        "level": 2
      },
      {
        "title": "Outcome",
        "content": "\n---\n\n**ed**\n\n**Data-driven approach** to determine daily staffing levels, **improving operational efficiency.**\n",
        "level": 2
      }
    ],
    "metadata": {
      "title": "Central Provident Fund (CPF) Board Manpower Optimisation System",
      "category": "project",
      "file_name": "Central Provident Fund (CPF) Board Manpower Optimi b2d449e2d8584adbaf3efcfdcede232c",
      "relative_path": "Chin Wei Ming’s Portfolio 28d2a0713ab449fa82d8851c163d4b1f/Projects aee4f34d22394d1690473e4917727405/Central Provident Fund (CPF) Board Manpower Optimi b2d449e2d8584adbaf3efcfdcede232c.md",
      "last_modified": 1749024948.6153882
    },
    "word_count": 332,
    "referenced_files": []
  },
  {
    "id": "Chin Wei Ming’s Portfolio 28d2a0713ab449fa82d8851c163d4b1f_Projects aee4f34d22394d1690473e4917727405_ReImagine Public Engagement (URA) 19bf57abcb4e80e9a12bf72588a5f7fb",
    "source_file": "data/raw/notion_export/Chin Wei Ming’s Portfolio 28d2a0713ab449fa82d8851c163d4b1f/Projects aee4f34d22394d1690473e4917727405/ReImagine Public Engagement (URA) 19bf57abcb4e80e9a12bf72588a5f7fb.md",
    "type": "markdown",
    "title": "ReImagine Public Engagement (URA)",
    "category": "project",
    "raw_content": "# ReImagine Public Engagement (URA)\n\nTimeline: September 9, 2024 → December 20, 2024\nClient: 60.006 Spatial Design Studio, Urban Redevelopment Board\nMy Role: Computer Vision Engineer, Front End Developer, UI/UX designer\nDeliverables: Enable urban planners to distill actionable outcomes., Enable users to express desired spatial edits., Integrate Artificial Intelligence to enhance user engagement.\nTools: Computer Vision, Figma, Generative AI, Git, Python, React\nDocument: ../Final_Report.pdf\nGithub: https://github.com/weetimo/spatialworld\n\n## Overview\n\n---\n\n![dfe9a804-9375-4661-935a-bf3eb74e9956.JPG](ReImagine%20Public%20Engagement%20(URA)%2019bf57abcb4e80e9a12bf72588a5f7fb/dfe9a804-9375-4661-935a-bf3eb74e9956.jpg)\n\nTo enhance urban planing through inclusive public engagement, I contributed to an **AI-driven application** designed for the **Urban Redevelopment Authority (URA)**. This application streamlines engagement sessions by leveraging **generative AI** technologies to visualise **public feedback** as **actionable design insights**.\n\n- AI-Powered Engagement: Integrated **Generative AI tools** (image inpainting, prompt upscaling, AI critique) to enhance public engagement quality.\n- Interactive Public Engagement Platform: Developed a **user-friendly web application** that allows participants to visually express their ideas, submit feedback, engage with AI-generated urban design proposals in real time.\n- Admin-Facing Platform: Designed and implemented an **admin dashboard** using **Figma for prototyping** and **React for front-end development**, streamlining the management of public input.\n- User Testing & Evaluation: Conducted real-world trials comparing **traditional and AI-enhanced engagement methods**, demonstrating improved participant **satisfaction, engagement, and usability**.\n\n## Problem Statement\n\n---\n\nHow might we integrate Artificial Intelligence (AI) to **enhance user engagement**, enabling users to **express desired space changes** and **distill actionable outcomes** from their feedback?\n\n![Screenshot 2025-02-15 at 9.08.45 PM.png](ReImagine%20Public%20Engagement%20(URA)%2019bf57abcb4e80e9a12bf72588a5f7fb/Screenshot_2025-02-15_at_9.08.45_PM.png)\n\n![Screenshot 2025-02-15 at 9.09.11 PM.png](ReImagine%20Public%20Engagement%20(URA)%2019bf57abcb4e80e9a12bf72588a5f7fb/Screenshot_2025-02-15_at_9.09.11_PM.png)\n\n### **Current Challenges in Public Engagement**\n\n- **Fragmented Workflow Due to Manual Toggling Between Applications**\n- **Disconnection Between Public Feedback and Urban Design**\n- **Difficulty in Translating Public Input into Actionable Outcomes**\n\n## Solution\n\n---\n\n### **1. AI-Driven Public Engagement Platform**\n\n- A web-based application designed to facilitate **seamless public participation**, allowing users to provide input on urban spaces through **text-based and visual interactions**.\n- Uses **Generative AI** (image inpainting, prompt upscaling, and AI critique) to **translate user ideas into visualised design concepts**, helping participants see the potential impact of their suggestions.\n- Users can **view and upvote** other participants' urban design ideas, fostering a **collaborative** highlighting the most popular community-driven solutions.\n\n[step2 pd5.mp4](ReImagine%20Public%20Engagement%20(URA)%2019bf57abcb4e80e9a12bf72588a5f7fb/step2_pd5.mp4)\n\n### **2. Real-Time Analytics & Insights for Urban Planners**\n\n- **AI-powered analytics dashboard** that provides **real-time tracking and categorisation** of public feedback.\n- **Automated trend analysis** to identify recurring themes, helping planners understand community priorities.\n- Data visualisation tools that summarise public sentiment and preferences, ensuring feedback directly informs urban planning decisions.\n\n**Create New Engagement Session**\n\n[step1 demo 2.mp4](ReImagine%20Public%20Engagement%20(URA)%2019bf57abcb4e80e9a12bf72588a5f7fb/step1_demo_2.mp4)\n\n**Public Engagement Analytics Dashboard**\n\n[step3 demo new.mp4](ReImagine%20Public%20Engagement%20(URA)%2019bf57abcb4e80e9a12bf72588a5f7fb/step3_demo_new.mp4)\n\n## Project video\n\n---\n\n[https://www.youtube.com/watch?v=3aYZVH-X-vY](https://www.youtube.com/watch?v=3aYZVH-X-vY)",
    "cleaned_content": "# ReImagine Public Engagement (URA)\n\nTimeline: September 9, 2024 → December 20, 2024\nClient: 60.006 Spatial Design Studio, Urban Redevelopment Board\nMy Role: Computer Vision Engineer, Front End Developer, UI/UX designer\nDeliverables: Enable urban planners to distill actionable outcomes., Enable users to express desired spatial edits., Integrate Artificial Intelligence to enhance user engagement.\nTools: Computer Vision, Figma, Generative AI, Git, Python, React\nDocument: ../Final_Report.pdf\nGithub: https://github.com/weetimo/spatialworld\n\n## Overview\n\n---\n\n![dfe9a804-9375-4661-935a-bf3eb74e9956.JPG](ReImagine Public Engagement (URA) 19bf57abcb4e80e9a12bf72588a5f7fb/dfe9a804-9375-4661-935a-bf3eb74e9956.jpg)\n\nTo enhance urban planing through inclusive public engagement, I contributed to an **AI-driven application** designed for the **Urban Redevelopment Authority (URA)**. This application streamlines engagement sessions by leveraging **generative AI** technologies to visualise **public feedback** as **actionable design insights**.\n\n- AI-Powered Engagement: Integrated **Generative AI tools** (image inpainting, prompt upscaling, AI critique) to enhance public engagement quality.\n- Interactive Public Engagement Platform: Developed a **user-friendly web application** that allows participants to visually express their ideas, submit feedback, engage with AI-generated urban design proposals in real time.\n- Admin-Facing Platform: Designed and implemented an **admin dashboard** using **Figma for prototyping** and **React for front-end development**, streamlining the management of public input.\n- User Testing & Evaluation: Conducted real-world trials comparing **traditional and AI-enhanced engagement methods**, demonstrating improved participant **satisfaction, engagement, and usability**.\n\n## Problem Statement\n\n---\n\nHow might we integrate Artificial Intelligence (AI) to **enhance user engagement**, enabling users to **express desired space changes** and **distill actionable outcomes** from their feedback?\n\n![Screenshot 2025-02-15 at 9.08.45 PM.png](ReImagine Public Engagement (URA) 19bf57abcb4e80e9a12bf72588a5f7fb/Screenshot_2025-02-15_at_9.08.45_PM.png)\n\n![Screenshot 2025-02-15 at 9.09.11 PM.png](ReImagine Public Engagement (URA) 19bf57abcb4e80e9a12bf72588a5f7fb/Screenshot_2025-02-15_at_9.09.11_PM.png)\n\n### **Current Challenges in Public Engagement**\n\n- **Fragmented Workflow Due to Manual Toggling Between Applications**\n- **Disconnection Between Public Feedback and Urban Design**\n- **Difficulty in Translating Public Input into Actionable Outcomes**\n\n## Solution\n\n---\n\n### **1. AI-Driven Public Engagement Platform**\n\n- A web-based application designed to facilitate **seamless public participation**, allowing users to provide input on urban spaces through **text-based and visual interactions**.\n- Uses **Generative AI** (image inpainting, prompt upscaling, and AI critique) to **translate user ideas into visualised design concepts**, helping participants see the potential impact of their suggestions.\n- Users can **view and upvote** other participants' urban design ideas, fostering a **collaborative** highlighting the most popular community-driven solutions.\n\n[step2 pd5.mp4](ReImagine Public Engagement (URA) 19bf57abcb4e80e9a12bf72588a5f7fb/step2_pd5.mp4)\n\n### **2. Real-Time Analytics & Insights for Urban Planners**\n\n- **AI-powered analytics dashboard** that provides **real-time tracking and categorisation** of public feedback.\n- **Automated trend analysis** to identify recurring themes, helping planners understand community priorities.\n- Data visualisation tools that summarise public sentiment and preferences, ensuring feedback directly informs urban planning decisions.\n\n**Create New Engagement Session**\n\n[step1 demo 2.mp4](ReImagine Public Engagement (URA) 19bf57abcb4e80e9a12bf72588a5f7fb/step1_demo_2.mp4)\n\n**Public Engagement Analytics Dashboard**\n\n[step3 demo new.mp4](ReImagine Public Engagement (URA) 19bf57abcb4e80e9a12bf72588a5f7fb/step3_demo_new.mp4)\n\n## Project video\n\n---\n\n[https://www.youtube.com/watch?v=3aYZVH-X-vY](https://www.youtube.com/watch?v=3aYZVH-X-vY)",
    "plain_text": "ReImagine Public Engagement (URA) Timeline: September 9, 2024 → December 20, 2024 Client: 60.006 Spatial Design Studio, Urban Redevelopment Board My Role: Computer Vision Engineer, Front End Developer, UI/UX designer Deliverables: Enable urban planners to distill actionable outcomes., Enable users to express desired spatial edits., Integrate Artificial Intelligence to enhance user engagement. Tools: Computer Vision, Figma, Generative AI, Git, Python, React Document: ../Final_Report.pdf Github: https://github.com/weetimo/spatialworld Overview To enhance urban planing through inclusive public engagement, I contributed to an AI-driven application designed for the Urban Redevelopment Authority (URA). This application streamlines engagement sessions by leveraging generative AI technologies to visualise public feedback as actionable design insights. AI-Powered Engagement: Integrated Generative AI tools (image inpainting, prompt upscaling, AI critique) to enhance public engagement quality. Interactive Public Engagement Platform: Developed a user-friendly web application that allows participants to visually express their ideas, submit feedback, engage with AI-generated urban design proposals in real time. Admin-Facing Platform: Designed and implemented an admin dashboard using Figma for prototyping and React for front-end development, streamlining the management of public input. User Testing & Evaluation: Conducted real-world trials comparing traditional and AI-enhanced engagement methods, demonstrating improved participant satisfaction, engagement, and usability. Problem Statement How might we integrate Artificial Intelligence (AI) to enhance user engagement, enabling users to express desired space changes and distill actionable outcomes from their feedback? Current Challenges in Public Engagement Fragmented Workflow Due to Manual Toggling Between Applications Disconnection Between Public Feedback and Urban Design Difficulty in Translating Public Input into Actionable Outcomes Solution 1. AI-Driven Public Engagement Platform A web-based application designed to facilitate seamless public participation, allowing users to provide input on urban spaces through text-based and visual interactions. Uses Generative AI (image inpainting, prompt upscaling, and AI critique) to translate user ideas into visualised design concepts, helping participants see the potential impact of their suggestions. Users can view and upvote other participants' urban design ideas, fostering a collaborative highlighting the most popular community-driven solutions. step2 pd5.mp4 2. Real-Time Analytics & Insights for Urban Planners AI-powered analytics dashboard that provides real-time tracking and categorisation of public feedback. Automated trend analysis to identify recurring themes, helping planners understand community priorities. Data visualisation tools that summarise public sentiment and preferences, ensuring feedback directly informs urban planning decisions. Create New Engagement Session step1 demo 2.mp4 Public Engagement Analytics Dashboard step3 demo new.mp4 Project video https://www.youtube.com/watch?v=3aYZVH-X-vY",
    "sections": [
      {
        "title": "ReImagine Public Engagement (URA)",
        "content": "\nTimeline: September 9, 2024 → December 20, 2024\nClient: 60.006 Spatial Design Studio, Urban Redevelopment Board\nMy Role: Computer Vision Engineer, Front End Developer, UI/UX designer\nDeliverables: Enable urban planners to distill actionable outcomes., Enable users to express desired spatial edits., Integrate Artificial Intelligence to enhance user engagement.\nTools: Computer Vision, Figma, Generative AI, Git, Python, React\nDocument: ../Final_Report.pdf\nGithub: https://github.com/weetimo/spatialworld\n\n",
        "level": 1
      },
      {
        "title": "Overview",
        "content": "\n---\n\n![dfe9a804-9375-4661-935a-bf3eb74e9956.JPG](ReImagine Public Engagement (URA) 19bf57abcb4e80e9a12bf72588a5f7fb/dfe9a804-9375-4661-935a-bf3eb74e9956.jpg)\n\nTo enhance urban planing through inclusive public engagement, I contributed to an **AI-driven application** designed for the **Urban Redevelopment Authority (URA)**. This application streamlines engagement sessions by leveraging **generative AI** technologies to visualise **public feedback** as **actionable design insights**.\n\n- AI-Powered Engagement: Integrated **Generative AI tools** (image inpainting, prompt upscaling, AI critique) to enhance public engagement quality.\n- Interactive Public Engagement Platform: Developed a **user-friendly web application** that allows participants to visually express their ideas, submit feedback, engage with AI-generated urban design proposals in real time.\n- Admin-Facing Platform: Designed and implemented an **admin dashboard** using **Figma for prototyping** and **React for front-end development**, streamlining the management of public input.\n- User Testing & Evaluation: Conducted real-world trials comparing **traditional and AI-enhanced engagement methods**, demonstrating improved participant **satisfaction, engagement, and usability**.\n\n",
        "level": 2
      },
      {
        "title": "Problem Statement",
        "content": "\n---\n\nHow might we integrate Artificial Intelligence (AI) to **enhance user engagement**, enabling users to **express desired space changes** and **distill actionable outcomes** from their feedback?\n\n![Screenshot 2025-02-15 at 9.08.45 PM.png](ReImagine Public Engagement (URA) 19bf57abcb4e80e9a12bf72588a5f7fb/Screenshot_2025-02-15_at_9.08.45_PM.png)\n\n![Screenshot 2025-02-15 at 9.09.11 PM.png](ReImagine Public Engagement (URA) 19bf57abcb4e80e9a12bf72588a5f7fb/Screenshot_2025-02-15_at_9.09.11_PM.png)\n\n",
        "level": 2
      },
      {
        "title": "**Current Challenges in Public Engagement**",
        "content": "\n- **Fragmented Workflow Due to Manual Toggling Between Applications**\n- **Disconnection Between Public Feedback and Urban Design**\n- **Difficulty in Translating Public Input into Actionable Outcomes**\n\n",
        "level": 3
      },
      {
        "title": "Solution",
        "content": "\n---\n\n",
        "level": 2
      },
      {
        "title": "**1. AI-Driven Public Engagement Platform**",
        "content": "\n- A web-based application designed to facilitate **seamless public participation**, allowing users to provide input on urban spaces through **text-based and visual interactions**.\n- Uses **Generative AI** (image inpainting, prompt upscaling, and AI critique) to **translate user ideas into visualised design concepts**, helping participants see the potential impact of their suggestions.\n- Users can **view and upvote** other participants' urban design ideas, fostering a **collaborative** highlighting the most popular community-driven solutions.\n\n[step2 pd5.mp4](ReImagine Public Engagement (URA) 19bf57abcb4e80e9a12bf72588a5f7fb/step2_pd5.mp4)\n\n",
        "level": 3
      },
      {
        "title": "**2. Real-Time Analytics & Insights for Urban Planners**",
        "content": "\n- **AI-powered analytics dashboard** that provides **real-time tracking and categorisation** of public feedback.\n- **Automated trend analysis** to identify recurring themes, helping planners understand community priorities.\n- Data visualisation tools that summarise public sentiment and preferences, ensuring feedback directly informs urban planning decisions.\n\n**Create New Engagement Session**\n\n[step1 demo 2.mp4](ReImagine Public Engagement (URA) 19bf57abcb4e80e9a12bf72588a5f7fb/step1_demo_2.mp4)\n\n**Public Engagement Analytics Dashboard**\n\n[step3 demo new.mp4](ReImagine Public Engagement (URA) 19bf57abcb4e80e9a12bf72588a5f7fb/step3_demo_new.mp4)\n\n",
        "level": 3
      },
      {
        "title": "Project video",
        "content": "\n---\n\n[https://www.youtube.com/watch?v=3aYZVH-X-vY](https://www.youtube.com/watch?v=3aYZVH-X-vY)\n",
        "level": 2
      }
    ],
    "metadata": {
      "title": "ReImagine Public Engagement (URA)",
      "category": "project",
      "file_name": "ReImagine Public Engagement (URA) 19bf57abcb4e80e9a12bf72588a5f7fb",
      "relative_path": "Chin Wei Ming’s Portfolio 28d2a0713ab449fa82d8851c163d4b1f/Projects aee4f34d22394d1690473e4917727405/ReImagine Public Engagement (URA) 19bf57abcb4e80e9a12bf72588a5f7fb.md",
      "last_modified": 1749024949.2715816
    },
    "word_count": 389,
    "referenced_files": []
  },
  {
    "id": "Chin Wei Ming’s Portfolio 28d2a0713ab449fa82d8851c163d4b1f_Projects aee4f34d22394d1690473e4917727405_Improving the Nothing Phone (1) 57a14cc2c8c34644bad668d0eb263291",
    "source_file": "data/raw/notion_export/Chin Wei Ming’s Portfolio 28d2a0713ab449fa82d8851c163d4b1f/Projects aee4f34d22394d1690473e4917727405/Improving the Nothing Phone (1) 57a14cc2c8c34644bad668d0eb263291.md",
    "type": "markdown",
    "title": "Improving the Nothing Phone (1)",
    "category": "project",
    "raw_content": "# Improving the Nothing Phone (1)\n\nTimeline: January 23, 2023 → April 29, 2024\nClient: SUTD\nMy Role: Python Programmer\nDeliverables: Seeking design opportunities for the Nothing Phone (1) for its next design iteration.\nTools: Natural Language Processing, Pandas library, Python, Web scraping\nDocument: ../AID_Project_2.pdf\n\n## Overview\n\n![Untitled](Improving%20the%20Nothing%20Phone%20(1)%2057a14cc2c8c34644bad668d0eb263291/Untitled.png)\n\n---\n\nWe developed a Python model to identify potential areas for product improvement by analysing online reviews, comments, and blog posts.\n\n## Data Collection\n\n---\n\n![Screenshot 2024-08-27 at 11.45.53 AM.png](Improving%20the%20Nothing%20Phone%20(1)%2057a14cc2c8c34644bad668d0eb263291/Screenshot_2024-08-27_at_11.45.53_AM.png)\n\n## Data Pre-processing\n\n---\n\n**Data Cleaning:**\n\n- Tokenization and lemmatization.\n- Removal of stopwords, emojis, links, symbols, and duplicate comments.\n- Lowercasing all text.\n- Detection of language and translation to English.\n\n## Data Analysis\n\n---\n\n**Sentiment Analysis:**\n\n- Utilised Hugging Face Transformers to analyze and categorize reviews as positive or negative.\n- Focused on extracting actionable product improvement suggestions from negative reviews, helping to pinpoint specific areas of concern raised by users.\n\n**Topic Modeling:**\n\n![Screenshot 2024-08-27 at 11.47.19 AM.png](Improving%20the%20Nothing%20Phone%20(1)%2057a14cc2c8c34644bad668d0eb263291/Screenshot_2024-08-27_at_11.47.19_AM.png)\n\n- Applied topic modelling techniques to classify comments into different categories, such as design, battery life, camera performance, etc.\n- This helped in organising the feedback into meaningful themes, making it easier to identify trends and prioritise areas for improvement.\n\n## Results\n\n---\n\n![Screenshot 2024-08-27 at 11.57.30 AM.png](Improving%20the%20Nothing%20Phone%20(1)%2057a14cc2c8c34644bad668d0eb263291/Screenshot_2024-08-27_at_11.57.30_AM.png)\n\nThe project identified three **key design opportunities** for the Nothing Phone (1):\n\n1. Establishing a **distinct identity** for the phone in the competitive smartphone market.\n2. Introducing **different sub-models** with **varying specifications and price** to cater to diverse customer needs.\n3. Designing a **new, innovative backing** for the phone to enhance its **aesthetic appeal and functionality.**",
    "cleaned_content": "# Improving the Nothing Phone (1)\n\nTimeline: January 23, 2023 → April 29, 2024\nClient: SUTD\nMy Role: Python Programmer\nDeliverables: Seeking design opportunities for the Nothing Phone (1) for its next design iteration.\nTools: Natural Language Processing, Pandas library, Python, Web scraping\nDocument: ../AID_Project_2.pdf\n\n## Overview\n\n![Untitled](Improving the Nothing Phone (1) 57a14cc2c8c34644bad668d0eb263291/Untitled.png)\n\n---\n\nWe developed a Python model to identify potential areas for product improvement by analysing online reviews, comments, and blog posts.\n\n## Data Collection\n\n---\n\n![Screenshot 2024-08-27 at 11.45.53 AM.png](Improving the Nothing Phone (1) 57a14cc2c8c34644bad668d0eb263291/Screenshot_2024-08-27_at_11.45.53_AM.png)\n\n## Data Pre-processing\n\n---\n\n**Data Cleaning:**\n\n- Tokenization and lemmatization.\n- Removal of stopwords, emojis, links, symbols, and duplicate comments.\n- Lowercasing all text.\n- Detection of language and translation to English.\n\n## Data Analysis\n\n---\n\n**Sentiment Analysis:**\n\n- Utilised Hugging Face Transformers to analyze and categorize reviews as positive or negative.\n- Focused on extracting actionable product improvement suggestions from negative reviews, helping to pinpoint specific areas of concern raised by users.\n\n**Topic Modeling:**\n\n![Screenshot 2024-08-27 at 11.47.19 AM.png](Improving the Nothing Phone (1) 57a14cc2c8c34644bad668d0eb263291/Screenshot_2024-08-27_at_11.47.19_AM.png)\n\n- Applied topic modelling techniques to classify comments into different categories, such as design, battery life, camera performance, etc.\n- This helped in organising the feedback into meaningful themes, making it easier to identify trends and prioritise areas for improvement.\n\n## Results\n\n---\n\n![Screenshot 2024-08-27 at 11.57.30 AM.png](Improving the Nothing Phone (1) 57a14cc2c8c34644bad668d0eb263291/Screenshot_2024-08-27_at_11.57.30_AM.png)\n\nThe project identified three **key design opportunities** for the Nothing Phone (1):\n\n1. Establishing a **distinct identity** for the phone in the competitive smartphone market.\n2. Introducing **different sub-models** with **varying specifications and price** to cater to diverse customer needs.\n3. Designing a **new, innovative backing** for the phone to enhance its **aesthetic appeal and functionality.**",
    "plain_text": "Improving the Nothing Phone (1) Timeline: January 23, 2023 → April 29, 2024 Client: SUTD My Role: Python Programmer Deliverables: Seeking design opportunities for the Nothing Phone (1) for its next design iteration. Tools: Natural Language Processing, Pandas library, Python, Web scraping Document: ../AID_Project_2.pdf Overview We developed a Python model to identify potential areas for product improvement by analysing online reviews, comments, and blog posts. Data Collection Data Pre-processing Data Cleaning: Tokenization and lemmatization. Removal of stopwords, emojis, links, symbols, and duplicate comments. Lowercasing all text. Detection of language and translation to English. Data Analysis Sentiment Analysis: Utilised Hugging Face Transformers to analyze and categorize reviews as positive or negative. Focused on extracting actionable product improvement suggestions from negative reviews, helping to pinpoint specific areas of concern raised by users. Topic Modeling: Applied topic modelling techniques to classify comments into different categories, such as design, battery life, camera performance, etc. This helped in organising the feedback into meaningful themes, making it easier to identify trends and prioritise areas for improvement. Results The project identified three key design opportunities for the Nothing Phone (1): Establishing a distinct identity for the phone in the competitive smartphone market. Introducing different sub-models with varying specifications and price to cater to diverse customer needs. Designing a new, innovative backing for the phone to enhance its aesthetic appeal and functionality.",
    "sections": [
      {
        "title": "Improving the Nothing Phone (1)",
        "content": "\nTimeline: January 23, 2023 → April 29, 2024\nClient: SUTD\nMy Role: Python Programmer\nDeliverables: Seeking design opportunities for the Nothing Phone (1) for its next design iteration.\nTools: Natural Language Processing, Pandas library, Python, Web scraping\nDocument: ../AID_Project_2.pdf\n\n",
        "level": 1
      },
      {
        "title": "Overview",
        "content": "\n![Untitled](Improving the Nothing Phone (1) 57a14cc2c8c34644bad668d0eb263291/Untitled.png)\n\n---\n\nWe developed a Python model to identify potential areas for product improvement by analysing online reviews, comments, and blog posts.\n\n",
        "level": 2
      },
      {
        "title": "Data Collection",
        "content": "\n---\n\n![Screenshot 2024-08-27 at 11.45.53 AM.png](Improving the Nothing Phone (1) 57a14cc2c8c34644bad668d0eb263291/Screenshot_2024-08-27_at_11.45.53_AM.png)\n\n",
        "level": 2
      },
      {
        "title": "Data Pre-processing",
        "content": "\n---\n\n**Data Cleaning:**\n\n- Tokenization and lemmatization.\n- Removal of stopwords, emojis, links, symbols, and duplicate comments.\n- Lowercasing all text.\n- Detection of language and translation to English.\n\n",
        "level": 2
      },
      {
        "title": "Data Analysis",
        "content": "\n---\n\n**Sentiment Analysis:**\n\n- Utilised Hugging Face Transformers to analyze and categorize reviews as positive or negative.\n- Focused on extracting actionable product improvement suggestions from negative reviews, helping to pinpoint specific areas of concern raised by users.\n\n**Topic Modeling:**\n\n![Screenshot 2024-08-27 at 11.47.19 AM.png](Improving the Nothing Phone (1) 57a14cc2c8c34644bad668d0eb263291/Screenshot_2024-08-27_at_11.47.19_AM.png)\n\n- Applied topic modelling techniques to classify comments into different categories, such as design, battery life, camera performance, etc.\n- This helped in organising the feedback into meaningful themes, making it easier to identify trends and prioritise areas for improvement.\n\n",
        "level": 2
      },
      {
        "title": "Results",
        "content": "\n---\n\n![Screenshot 2024-08-27 at 11.57.30 AM.png](Improving the Nothing Phone (1) 57a14cc2c8c34644bad668d0eb263291/Screenshot_2024-08-27_at_11.57.30_AM.png)\n\nThe project identified three **key design opportunities** for the Nothing Phone (1):\n\n1. Establishing a **distinct identity** for the phone in the competitive smartphone market.\n2. Introducing **different sub-models** with **varying specifications and price** to cater to diverse customer needs.\n3. Designing a **new, innovative backing** for the phone to enhance its **aesthetic appeal and functionality.**\n",
        "level": 2
      }
    ],
    "metadata": {
      "title": "Improving the Nothing Phone (1)",
      "category": "project",
      "file_name": "Improving the Nothing Phone (1) 57a14cc2c8c34644bad668d0eb263291",
      "relative_path": "Chin Wei Ming’s Portfolio 28d2a0713ab449fa82d8851c163d4b1f/Projects aee4f34d22394d1690473e4917727405/Improving the Nothing Phone (1) 57a14cc2c8c34644bad668d0eb263291.md",
      "last_modified": 1749024948.9939835
    },
    "word_count": 224,
    "referenced_files": []
  },
  {
    "id": "Chin Wei Ming’s Portfolio 28d2a0713ab449fa82d8851c163d4b1f_Projects aee4f34d22394d1690473e4917727405_The Guiding Hand 2d1bc872300e4a248f1b3a8ef4d2384d",
    "source_file": "data/raw/notion_export/Chin Wei Ming’s Portfolio 28d2a0713ab449fa82d8851c163d4b1f/Projects aee4f34d22394d1690473e4917727405/The Guiding Hand 2d1bc872300e4a248f1b3a8ef4d2384d.md",
    "type": "markdown",
    "title": "The Guiding Hand",
    "category": "project",
    "raw_content": "# The Guiding Hand\n\nTimeline: May 8, 2023 → August 25, 2024\nClient: Gebirah, SUTD, Service Design Studio\nMy Role: ML specialist, Testing Software Engineer, UI Designer\nDeliverables: Valuing Women's Choices No Matter the Road., Worked with Gebirah to tackle the issue of woman facing unplanned pregnancy in Singapore\nTools: Figma, Javascript, Puppeteer, Python\nDocument: https://sites.google.com/view/team10-echolestia/home\n\n## **Overview**\n\n![Screenshot 2023-08-13 225841.png](The%20Guiding%20Hand%202d1bc872300e4a248f1b3a8ef4d2384d/Screenshot_2023-08-13_225841.png)\n\n---\n\n**Addressing High Abortion Rates and Declining Birth Rates in Singapore**\n\n**Objective:** Collaborate with Gebirah, a non-profit organisation, to tackle pressing issues related to high abortion rates, unsafe practices, and declining birth rates in Singapore. In 2020, there were 4,029 recorded abortions, averaging 336 per month, some involving underage girls. These challenges exacerbate the nation's aging population and endanger maternal and fetal health.\n\n**Key Challenges:**\n\n- **Access to Support:** How can we make it easier for women facing unplanned pregnancies to access personalised assistance, connect with professional counselors, and receive necessary emotional support without overwhelming or complicating the process?\n- **Streamlining Services:** How can we streamline the handling of inquiries and prioritize cases effectively without compromising service quality or burdening administrators with complex features?\n\n**Our Role:** With a team of six, we aimed to unify information from independent help centers and the government, providing a comprehensive support system for those in need. Our focus was on simplifying access to resources, improving case management, and ensuring the delivery of compassionate, effective care.\n\n## Automated software testing system\n\n---\n\nDeveloped an automated testing system for both the client-facing phone app and web app to ensure functionality and reliability.\n\n- Utilised Puppeteer in JavaScript to write test cases.\n- Automated the testing process to verify that each component of the apps functions as expected.\n\nThe automated system enhanced the efficiency of testing, ensuring consistent performance across both platforms.\n\n[1.mp4](The%20Guiding%20Hand%202d1bc872300e4a248f1b3a8ef4d2384d/1.mp4)\n\n## AI Features\n\n---\n\n- **24/7 Medical Support:** Integrated with the ChatGPT API, further fine-tuned with relevant medical information, allowing users to access continuous medical support.\n\n[Untitled.mp4](The%20Guiding%20Hand%202d1bc872300e4a248f1b3a8ef4d2384d/Untitled.mp4)\n\n- **Sentiment Analysis:** Implemented a sentiment analysis feature using a Hugging Face transformer model, trained to detect harmful text. When harmful content is detected, it automatically flags it for counsellors.\n- **Chat Summary:** Provides counselors with a quick summary of the chat history, facilitating efficient review and follow-up.\n    \n    [Screen Recording 2023-08-10 at 3.38.42 AM.mp4](The%20Guiding%20Hand%202d1bc872300e4a248f1b3a8ef4d2384d/Screen_Recording_2023-08-10_at_3.38.42_AM.mp4)\n    \n\n## Final outcome of the project\n\n---\n\n[https://www.youtube.com/watch?v=y1QmRHpY6l4&t=1s](https://www.youtube.com/watch?v=y1QmRHpY6l4&t=1s)\n\n---",
    "cleaned_content": "# The Guiding Hand\n\nTimeline: May 8, 2023 → August 25, 2024\nClient: Gebirah, SUTD, Service Design Studio\nMy Role: ML specialist, Testing Software Engineer, UI Designer\nDeliverables: Valuing Women's Choices No Matter the Road., Worked with Gebirah to tackle the issue of woman facing unplanned pregnancy in Singapore\nTools: Figma, Javascript, Puppeteer, Python\nDocument: https://sites.google.com/view/team10-echolestia/home\n\n## **Overview**\n\n![Image: Screenshot 2023-08-13 225841.png]\n\n---\n\n**Addressing High Abortion Rates and Declining Birth Rates in Singapore**\n\n**Objective:** Collaborate with Gebirah, a non-profit organisation, to tackle pressing issues related to high abortion rates, unsafe practices, and declining birth rates in Singapore. In 2020, there were 4,029 recorded abortions, averaging 336 per month, some involving underage girls. These challenges exacerbate the nation's aging population and endanger maternal and fetal health.\n\n**Key Challenges:**\n\n- **Access to Support:** How can we make it easier for women facing unplanned pregnancies to access personalised assistance, connect with professional counselors, and receive necessary emotional support without overwhelming or complicating the process?\n- **Streamlining Services:** How can we streamline the handling of inquiries and prioritize cases effectively without compromising service quality or burdening administrators with complex features?\n\n**Our Role:** With a team of six, we aimed to unify information from independent help centers and the government, providing a comprehensive support system for those in need. Our focus was on simplifying access to resources, improving case management, and ensuring the delivery of compassionate, effective care.\n\n## Automated software testing system\n\n---\n\nDeveloped an automated testing system for both the client-facing phone app and web app to ensure functionality and reliability.\n\n- Utilised Puppeteer in JavaScript to write test cases.\n- Automated the testing process to verify that each component of the apps functions as expected.\n\nThe automated system enhanced the efficiency of testing, ensuring consistent performance across both platforms.\n\n[Image: 1.mp4]\n\n## AI Features\n\n---\n\n- **24/7 Medical Support:** Integrated with the ChatGPT API, further fine-tuned with relevant medical information, allowing users to access continuous medical support.\n\n[Image: Untitled.mp4]\n\n- **Sentiment Analysis:** Implemented a sentiment analysis feature using a Hugging Face transformer model, trained to detect harmful text. When harmful content is detected, it automatically flags it for counsellors.\n- **Chat Summary:** Provides counselors with a quick summary of the chat history, facilitating efficient review and follow-up.\n \n [Image: Screen Recording 2023-08-10 at 3.38.42 AM.mp4]\n\n## Final outcome of the project\n\n---\n\n[https://www.youtube.com/watch?v=y1QmRHpY6l4&t=1s](https://www.youtube.com/watch?v=y1QmRHpY6l4&t=1s)\n\n---",
    "plain_text": "The Guiding Hand Timeline: May 8, 2023 → August 25, 2024 Client: Gebirah, SUTD, Service Design Studio My Role: ML specialist, Testing Software Engineer, UI Designer Deliverables: Valuing Women's Choices No Matter the Road., Worked with Gebirah to tackle the issue of woman facing unplanned pregnancy in Singapore Tools: Figma, Javascript, Puppeteer, Python Document: https://sites.google.com/view/team10-echolestia/home Overview ![Image: Screenshot 2023-08-13 225841.png] Addressing High Abortion Rates and Declining Birth Rates in Singapore Objective: Collaborate with Gebirah, a non-profit organisation, to tackle pressing issues related to high abortion rates, unsafe practices, and declining birth rates in Singapore. In 2020, there were 4,029 recorded abortions, averaging 336 per month, some involving underage girls. These challenges exacerbate the nation's aging population and endanger maternal and fetal health. Key Challenges: Access to Support: How can we make it easier for women facing unplanned pregnancies to access personalised assistance, connect with professional counselors, and receive necessary emotional support without overwhelming or complicating the process? Streamlining Services: How can we streamline the handling of inquiries and prioritize cases effectively without compromising service quality or burdening administrators with complex features? Our Role: With a team of six, we aimed to unify information from independent help centers and the government, providing a comprehensive support system for those in need. Our focus was on simplifying access to resources, improving case management, and ensuring the delivery of compassionate, effective care. Automated software testing system Developed an automated testing system for both the client-facing phone app and web app to ensure functionality and reliability. Utilised Puppeteer in JavaScript to write test cases. Automated the testing process to verify that each component of the apps functions as expected. The automated system enhanced the efficiency of testing, ensuring consistent performance across both platforms. [Image: 1.mp4] AI Features 24/7 Medical Support: Integrated with the ChatGPT API, further fine-tuned with relevant medical information, allowing users to access continuous medical support. [Image: Untitled.mp4] Sentiment Analysis: Implemented a sentiment analysis feature using a Hugging Face transformer model, trained to detect harmful text. When harmful content is detected, it automatically flags it for counsellors. Chat Summary: Provides counselors with a quick summary of the chat history, facilitating efficient review and follow-up. [Image: Screen Recording 2023-08-10 at 3.38.42 AM.mp4] Final outcome of the project https://www.youtube.com/watch?v=y1QmRHpY6l4&t=1s",
    "sections": [
      {
        "title": "The Guiding Hand",
        "content": "\nTimeline: May 8, 2023 → August 25, 2024\nClient: Gebirah, SUTD, Service Design Studio\nMy Role: ML specialist, Testing Software Engineer, UI Designer\nDeliverables: Valuing Women's Choices No Matter the Road., Worked with Gebirah to tackle the issue of woman facing unplanned pregnancy in Singapore\nTools: Figma, Javascript, Puppeteer, Python\nDocument: https://sites.google.com/view/team10-echolestia/home\n\n",
        "level": 1
      },
      {
        "title": "**Overview**",
        "content": "\n![Image: Screenshot 2023-08-13 225841.png]\n\n---\n\n**Addressing High Abortion Rates and Declining Birth Rates in Singapore**\n\n**Objective:** Collaborate with Gebirah, a non-profit organisation, to tackle pressing issues related to high abortion rates, unsafe practices, and declining birth rates in Singapore. In 2020, there were 4,029 recorded abortions, averaging 336 per month, some involving underage girls. These challenges exacerbate the nation's aging population and endanger maternal and fetal health.\n\n**Key Challenges:**\n\n- **Access to Support:** How can we make it easier for women facing unplanned pregnancies to access personalised assistance, connect with professional counselors, and receive necessary emotional support without overwhelming or complicating the process?\n- **Streamlining Services:** How can we streamline the handling of inquiries and prioritize cases effectively without compromising service quality or burdening administrators with complex features?\n\n**Our Role:** With a team of six, we aimed to unify information from independent help centers and the government, providing a comprehensive support system for those in need. Our focus was on simplifying access to resources, improving case management, and ensuring the delivery of compassionate, effective care.\n\n",
        "level": 2
      },
      {
        "title": "Automated software testing system",
        "content": "\n---\n\nDeveloped an automated testing system for both the client-facing phone app and web app to ensure functionality and reliability.\n\n- Utilised Puppeteer in JavaScript to write test cases.\n- Automated the testing process to verify that each component of the apps functions as expected.\n\nThe automated system enhanced the efficiency of testing, ensuring consistent performance across both platforms.\n\n[Image: 1.mp4]\n\n",
        "level": 2
      },
      {
        "title": "AI Features",
        "content": "\n---\n\n- **24/7 Medical Support:** Integrated with the ChatGPT API, further fine-tuned with relevant medical information, allowing users to access continuous medical support.\n\n[Image: Untitled.mp4]\n\n- **Sentiment Analysis:** Implemented a sentiment analysis feature using a Hugging Face transformer model, trained to detect harmful text. When harmful content is detected, it automatically flags it for counsellors.\n- **Chat Summary:** Provides counselors with a quick summary of the chat history, facilitating efficient review and follow-up.\n \n [Image: Screen Recording 2023-08-10 at 3.38.42 AM.mp4]\n\n",
        "level": 2
      },
      {
        "title": "Final outcome of the project",
        "content": "\n---\n\n[https://www.youtube.com/watch?v=y1QmRHpY6l4&t=1s](https://www.youtube.com/watch?v=y1QmRHpY6l4&t=1s)\n\n---\n",
        "level": 2
      }
    ],
    "metadata": {
      "title": "The Guiding Hand",
      "category": "project",
      "file_name": "The Guiding Hand 2d1bc872300e4a248f1b3a8ef4d2384d",
      "relative_path": "Chin Wei Ming’s Portfolio 28d2a0713ab449fa82d8851c163d4b1f/Projects aee4f34d22394d1690473e4917727405/The Guiding Hand 2d1bc872300e4a248f1b3a8ef4d2384d.md",
      "last_modified": 1749024949.4710138
    },
    "word_count": 374,
    "referenced_files": [
      {
        "name": "Screenshot 2023-08-13 225841.png",
        "path": "The%20Guiding%20Hand%202d1bc872300e4a248f1b3a8ef4d2384d/Screenshot_2023-08-13_225841.png",
        "type": "png"
      },
      {
        "name": "1.mp4",
        "path": "The%20Guiding%20Hand%202d1bc872300e4a248f1b3a8ef4d2384d/1.mp4",
        "type": "mp4"
      },
      {
        "name": "Untitled.mp4",
        "path": "The%20Guiding%20Hand%202d1bc872300e4a248f1b3a8ef4d2384d/Untitled.mp4",
        "type": "mp4"
      },
      {
        "name": "Screen Recording 2023-08-10 at 3.38.42 AM.mp4",
        "path": "The%20Guiding%20Hand%202d1bc872300e4a248f1b3a8ef4d2384d/Screen_Recording_2023-08-10_at_3.38.42_AM.mp4",
        "type": "mp4"
      }
    ]
  },
  {
    "id": "Chin Wei Ming’s Portfolio 28d2a0713ab449fa82d8851c163d4b1f_Projects aee4f34d22394d1690473e4917727405_Re-thinking the EVAM rocker cfa2ad61db6c496792c5859ae438c106",
    "source_file": "data/raw/notion_export/Chin Wei Ming’s Portfolio 28d2a0713ab449fa82d8851c163d4b1f/Projects aee4f34d22394d1690473e4917727405/Re-thinking the EVAM rocker cfa2ad61db6c496792c5859ae438c106.md",
    "type": "markdown",
    "title": "Re-thinking the EVAM rocker.",
    "category": "project",
    "raw_content": "# Re-thinking the EVAM rocker.\n\nTimeline: January 23, 2023 → April 29, 2024\nClient: SUTD\nMy Role: 3D designer, Innovator\nDeliverables: Promote material savings and energy savings in the rocker design.\nTools: Adobe Illustrator, Fusion 360, Generative Design\nDocument: ../EVAM_rocker.pdf\n\n## Overview\n\n![Screenshot 2023-04-05 at 12.26.23 AM.png](Re-thinking%20the%20EVAM%20rocker%20cfa2ad61db6c496792c5859ae438c106/Screenshot_2023-04-05_at_12.26.23_AM.png)\n\n---\n\n**Optimising Rocker Design for Material and Energy Savings through Additive Manufacturing**\n\n- Our task was to optimise the rocker component to reduce mass and energy usage.\n\n**Approach:**\n\n- **Physics Analysis:** We first studied the physics of the original rocker to understand its load-bearing requirements.\n- **Generative Design:** Used Fusion 360’s generative design tools to create innovative rocker designs that meet the required loads and constraints.\n- **Material Analysis:** Conducted material analysis to identify the best options for maximising energy and mass savings.\n- **Life Cycle Analysis:** Compared the new and original designs, resulting in a 72% reduction in CO2 emissions.\n\n## Results\n\n---\n\n### 60%\n\nreduction in mass for the EVAM’s rocker component through the new design.\n\n### 72%\n\ndecrease in CO2 emission for the EVAM’s rocker component through the new design.\n\n## Final Product\n\n---\n\n![1.png](Re-thinking%20the%20EVAM%20rocker%20cfa2ad61db6c496792c5859ae438c106/1.png)\n\n![1.png](Re-thinking%20the%20EVAM%20rocker%20cfa2ad61db6c496792c5859ae438c106/1%201.png)",
    "cleaned_content": "# Re-thinking the EVAM rocker.\n\nTimeline: January 23, 2023 → April 29, 2024\nClient: SUTD\nMy Role: 3D designer, Innovator\nDeliverables: Promote material savings and energy savings in the rocker design.\nTools: Adobe Illustrator, Fusion 360, Generative Design\nDocument: ../EVAM_rocker.pdf\n\n## Overview\n\n![Image: Screenshot 2023-04-05 at 12.26.23 AM.png]\n\n---\n\n**Optimising Rocker Design for Material and Energy Savings through Additive Manufacturing**\n\n- Our task was to optimise the rocker component to reduce mass and energy usage.\n\n**Approach:**\n\n- **Physics Analysis:** We first studied the physics of the original rocker to understand its load-bearing requirements.\n- **Generative Design:** Used Fusion 360’s generative design tools to create innovative rocker designs that meet the required loads and constraints.\n- **Material Analysis:** Conducted material analysis to identify the best options for maximising energy and mass savings.\n- **Life Cycle Analysis:** Compared the new and original designs, resulting in a 72% reduction in CO2 emissions.\n\n## Results\n\n---\n\n### 60%\n\nreduction in mass for the EVAM’s rocker component through the new design.\n\n### 72%\n\ndecrease in CO2 emission for the EVAM’s rocker component through the new design.\n\n## Final Product\n\n---\n\n![Image: 1.png]\n\n![Image: 1.png]",
    "plain_text": "Re-thinking the EVAM rocker. Timeline: January 23, 2023 → April 29, 2024 Client: SUTD My Role: 3D designer, Innovator Deliverables: Promote material savings and energy savings in the rocker design. Tools: Adobe Illustrator, Fusion 360, Generative Design Document: ../EVAM_rocker.pdf Overview ![Image: Screenshot 2023-04-05 at 12.26.23 AM.png] Optimising Rocker Design for Material and Energy Savings through Additive Manufacturing Our task was to optimise the rocker component to reduce mass and energy usage. Approach: Physics Analysis: We first studied the physics of the original rocker to understand its load-bearing requirements. Generative Design: Used Fusion 360’s generative design tools to create innovative rocker designs that meet the required loads and constraints. Material Analysis: Conducted material analysis to identify the best options for maximising energy and mass savings. Life Cycle Analysis: Compared the new and original designs, resulting in a 72% reduction in CO2 emissions. Results 60% reduction in mass for the EVAM’s rocker component through the new design. 72% decrease in CO2 emission for the EVAM’s rocker component through the new design. Final Product ![Image: 1.png] ![Image: 1.png]",
    "sections": [
      {
        "title": "Re-thinking the EVAM rocker.",
        "content": "\nTimeline: January 23, 2023 → April 29, 2024\nClient: SUTD\nMy Role: 3D designer, Innovator\nDeliverables: Promote material savings and energy savings in the rocker design.\nTools: Adobe Illustrator, Fusion 360, Generative Design\nDocument: ../EVAM_rocker.pdf\n\n",
        "level": 1
      },
      {
        "title": "Overview",
        "content": "\n![Image: Screenshot 2023-04-05 at 12.26.23 AM.png]\n\n---\n\n**Optimising Rocker Design for Material and Energy Savings through Additive Manufacturing**\n\n- Our task was to optimise the rocker component to reduce mass and energy usage.\n\n**Approach:**\n\n- **Physics Analysis:** We first studied the physics of the original rocker to understand its load-bearing requirements.\n- **Generative Design:** Used Fusion 360’s generative design tools to create innovative rocker designs that meet the required loads and constraints.\n- **Material Analysis:** Conducted material analysis to identify the best options for maximising energy and mass savings.\n- **Life Cycle Analysis:** Compared the new and original designs, resulting in a 72% reduction in CO2 emissions.\n\n",
        "level": 2
      },
      {
        "title": "Results",
        "content": "\n---\n\n",
        "level": 2
      },
      {
        "title": "60%",
        "content": "\nreduction in mass for the EVAM’s rocker component through the new design.\n\n",
        "level": 3
      },
      {
        "title": "72%",
        "content": "\ndecrease in CO2 emission for the EVAM’s rocker component through the new design.\n\n",
        "level": 3
      },
      {
        "title": "Final Product",
        "content": "\n---\n\n![Image: 1.png]\n\n![Image: 1.png]\n",
        "level": 2
      }
    ],
    "metadata": {
      "title": "Re-thinking the EVAM rocker.",
      "category": "project",
      "file_name": "Re-thinking the EVAM rocker cfa2ad61db6c496792c5859ae438c106",
      "relative_path": "Chin Wei Ming’s Portfolio 28d2a0713ab449fa82d8851c163d4b1f/Projects aee4f34d22394d1690473e4917727405/Re-thinking the EVAM rocker cfa2ad61db6c496792c5859ae438c106.md",
      "last_modified": 1749024949.0880842
    },
    "word_count": 175,
    "referenced_files": [
      {
        "name": "Screenshot 2023-04-05 at 12.26.23 AM.png",
        "path": "Re-thinking%20the%20EVAM%20rocker%20cfa2ad61db6c496792c5859ae438c106/Screenshot_2023-04-05_at_12.26.23_AM.png",
        "type": "png"
      },
      {
        "name": "1.png",
        "path": "Re-thinking%20the%20EVAM%20rocker%20cfa2ad61db6c496792c5859ae438c106/1.png",
        "type": "png"
      },
      {
        "name": "1.png",
        "path": "Re-thinking%20the%20EVAM%20rocker%20cfa2ad61db6c496792c5859ae438c106/1%201.png",
        "type": "png"
      }
    ]
  },
  {
    "id": "Chin Wei Ming’s Portfolio 28d2a0713ab449fa82d8851c163d4b1f_Projects aee4f34d22394d1690473e4917727405_Designing the EVAM’s interior 1ac0d79891964c80a91be7094bed7c26",
    "source_file": "data/raw/notion_export/Chin Wei Ming’s Portfolio 28d2a0713ab449fa82d8851c163d4b1f/Projects aee4f34d22394d1690473e4917727405/Designing the EVAM’s interior 1ac0d79891964c80a91be7094bed7c26.md",
    "type": "markdown",
    "title": "Designing the EVAM’s interior",
    "category": "project",
    "raw_content": "# Designing the EVAM’s interior\n\nTimeline: January 23, 2023 → April 29, 2024\nClient: Product Design Studio, SUTD, SUTD EVAM Team\nMy Role: 3D designer, Innovator, Prototype designer\nDeliverables: Enhancing the user experience of the EVAM with added lightness.\nTools: 3D printing, Adobe Illustrator, Fusion 360, Generative Design\nDocument: ../Product_Design_Studio.pdf\n\n## Overview\n\n![Untitled](Designing%20the%20EVAM%E2%80%99s%20interior%201ac0d79891964c80a91be7094bed7c26/Untitled.jpeg)\n\n---\n\n### **Interior Design for SUTD's EVAM (Electric Vehicle Additive Manufactured)**\n\n**Objective:** Design the interior of EVAM, SUTD’s F1-themed electric vehicle, which arrived as a skeleton with no interior design. The goal was to address client concerns and reflect SUTD’s identity.\n\n**Approach:**\n\n- **Client Requirements:** Focused on issues such as ease of entry and exit, designing features like armrests and side compartments for both front and rear seats, and a leg and heel rest for the driver. These features included step platforms and handles to facilitate access for elderly passengers and children.\n- **Design Development:** Over 14 weeks, our team produced a vision render for the EVAM’s interior and developed physical prototypes of the steering wheel, dashboard UI, and screens for both driver and passenger.\n\n**My Deliverables**:\n\n- **Design Solutions:** Addressed key issues by designing practical components to improve vehicle accessibility and comfort.\n- **Prototyping:** Developed physical prototypes of the steering wheel, and passenger and driver screens.\n\n**Learning Outcomes:**\n\n- Emphasised the importance of storyboarding to effectively communicate ideas.\n- Gained experience in hand sketching for initial ideation, producing numerous quick sketches to explore concepts.\n- Created a mood board to establish the design tone, feel, and identity, ensuring uniformity across all components.\n\n## Design Mood-Board\n\n---\n\n![Screenshot 2024-08-27 at 2.56.17 PM.png](Designing%20the%20EVAM%E2%80%99s%20interior%201ac0d79891964c80a91be7094bed7c26/Screenshot_2024-08-27_at_2.56.17_PM.png)\n\n## Final Design\n\n---\n\n![Untitled](Designing%20the%20EVAM%E2%80%99s%20interior%201ac0d79891964c80a91be7094bed7c26/Untitled%201.jpeg)\n\n![Untitled](Designing%20the%20EVAM%E2%80%99s%20interior%201ac0d79891964c80a91be7094bed7c26/Untitled%202.jpeg)\n\n![Screenshot 2024-08-27 at 3.15.47 PM.png](Designing%20the%20EVAM%E2%80%99s%20interior%201ac0d79891964c80a91be7094bed7c26/Screenshot_2024-08-27_at_3.15.47_PM.png)\n\n![Screenshot 2024-08-27 at 3.16.44 PM.png](Designing%20the%20EVAM%E2%80%99s%20interior%201ac0d79891964c80a91be7094bed7c26/Screenshot_2024-08-27_at_3.16.44_PM.png)\n\n![Screenshot 2024-08-27 at 3.16.59 PM.png](Designing%20the%20EVAM%E2%80%99s%20interior%201ac0d79891964c80a91be7094bed7c26/Screenshot_2024-08-27_at_3.16.59_PM.png)\n\n![Screenshot 2024-08-27 at 3.17.37 PM.png](Designing%20the%20EVAM%E2%80%99s%20interior%201ac0d79891964c80a91be7094bed7c26/Screenshot_2024-08-27_at_3.17.37_PM.png)\n\n## Physical Prototype\n\n---\n\n![Untitled](Designing%20the%20EVAM%E2%80%99s%20interior%201ac0d79891964c80a91be7094bed7c26/Untitled%203.jpeg)\n\n![Screenshot 2024-08-27 at 3.19.41 PM.png](Designing%20the%20EVAM%E2%80%99s%20interior%201ac0d79891964c80a91be7094bed7c26/Screenshot_2024-08-27_at_3.19.41_PM.png)\n\n![Screenshot 2024-08-27 at 3.20.08 PM.png](Designing%20the%20EVAM%E2%80%99s%20interior%201ac0d79891964c80a91be7094bed7c26/Screenshot_2024-08-27_at_3.20.08_PM.png)\n\n![Screenshot 2024-08-27 at 3.13.35 PM.png](Designing%20the%20EVAM%E2%80%99s%20interior%201ac0d79891964c80a91be7094bed7c26/Screenshot_2024-08-27_at_3.13.35_PM.png)\n\n![Screenshot 2024-08-27 at 3.21.56 PM.png](Designing%20the%20EVAM%E2%80%99s%20interior%201ac0d79891964c80a91be7094bed7c26/Screenshot_2024-08-27_at_3.21.56_PM.png)",
    "cleaned_content": "# Designing the EVAM’s interior\n\nTimeline: January 23, 2023 → April 29, 2024\nClient: Product Design Studio, SUTD, SUTD EVAM Team\nMy Role: 3D designer, Innovator, Prototype designer\nDeliverables: Enhancing the user experience of the EVAM with added lightness.\nTools: 3D printing, Adobe Illustrator, Fusion 360, Generative Design\nDocument: ../Product_Design_Studio.pdf\n\n## Overview\n\n![Image: Untitled]\n\n---\n\n### **Interior Design for SUTD's EVAM (Electric Vehicle Additive Manufactured)**\n\n**Objective:** Design the interior of EVAM, SUTD’s F1-themed electric vehicle, which arrived as a skeleton with no interior design. The goal was to address client concerns and reflect SUTD’s identity.\n\n**Approach:**\n\n- **Client Requirements:** Focused on issues such as ease of entry and exit, designing features like armrests and side compartments for both front and rear seats, and a leg and heel rest for the driver. These features included step platforms and handles to facilitate access for elderly passengers and children.\n- **Design Development:** Over 14 weeks, our team produced a vision render for the EVAM’s interior and developed physical prototypes of the steering wheel, dashboard UI, and screens for both driver and passenger.\n\n**My Deliverables**:\n\n- **Design Solutions:** Addressed key issues by designing practical components to improve vehicle accessibility and comfort.\n- **Prototyping:** Developed physical prototypes of the steering wheel, and passenger and driver screens.\n\n**Learning Outcomes:**\n\n- Emphasised the importance of storyboarding to effectively communicate ideas.\n- Gained experience in hand sketching for initial ideation, producing numerous quick sketches to explore concepts.\n- Created a mood board to establish the design tone, feel, and identity, ensuring uniformity across all components.\n\n## Design Mood-Board\n\n---\n\n![Image: Screenshot 2024-08-27 at 2.56.17 PM.png]\n\n## Final Design\n\n---\n\n![Image: Untitled]\n\n![Image: Untitled]\n\n![Image: Screenshot 2024-08-27 at 3.15.47 PM.png]\n\n![Image: Screenshot 2024-08-27 at 3.16.44 PM.png]\n\n![Image: Screenshot 2024-08-27 at 3.16.59 PM.png]\n\n![Image: Screenshot 2024-08-27 at 3.17.37 PM.png]\n\n## Physical Prototype\n\n---\n\n![Image: Untitled]\n\n![Image: Screenshot 2024-08-27 at 3.19.41 PM.png]\n\n![Image: Screenshot 2024-08-27 at 3.20.08 PM.png]\n\n![Image: Screenshot 2024-08-27 at 3.13.35 PM.png]\n\n![Image: Screenshot 2024-08-27 at 3.21.56 PM.png]",
    "plain_text": "Designing the EVAM’s interior Timeline: January 23, 2023 → April 29, 2024 Client: Product Design Studio, SUTD, SUTD EVAM Team My Role: 3D designer, Innovator, Prototype designer Deliverables: Enhancing the user experience of the EVAM with added lightness. Tools: 3D printing, Adobe Illustrator, Fusion 360, Generative Design Document: ../Product_Design_Studio.pdf Overview ![Image: Untitled] Interior Design for SUTD's EVAM (Electric Vehicle Additive Manufactured) Objective: Design the interior of EVAM, SUTD’s F1-themed electric vehicle, which arrived as a skeleton with no interior design. The goal was to address client concerns and reflect SUTD’s identity. Approach: Client Requirements: Focused on issues such as ease of entry and exit, designing features like armrests and side compartments for both front and rear seats, and a leg and heel rest for the driver. These features included step platforms and handles to facilitate access for elderly passengers and children. Design Development: Over 14 weeks, our team produced a vision render for the EVAM’s interior and developed physical prototypes of the steering wheel, dashboard UI, and screens for both driver and passenger. My Deliverables: Design Solutions: Addressed key issues by designing practical components to improve vehicle accessibility and comfort. Prototyping: Developed physical prototypes of the steering wheel, and passenger and driver screens. Learning Outcomes: Emphasised the importance of storyboarding to effectively communicate ideas. Gained experience in hand sketching for initial ideation, producing numerous quick sketches to explore concepts. Created a mood board to establish the design tone, feel, and identity, ensuring uniformity across all components. Design Mood-Board ![Image: Screenshot 2024-08-27 at 2.56.17 PM.png] Final Design ![Image: Untitled] ![Image: Untitled] ![Image: Screenshot 2024-08-27 at 3.15.47 PM.png] ![Image: Screenshot 2024-08-27 at 3.16.44 PM.png] ![Image: Screenshot 2024-08-27 at 3.16.59 PM.png] ![Image: Screenshot 2024-08-27 at 3.17.37 PM.png] Physical Prototype ![Image: Untitled] ![Image: Screenshot 2024-08-27 at 3.19.41 PM.png] ![Image: Screenshot 2024-08-27 at 3.20.08 PM.png] ![Image: Screenshot 2024-08-27 at 3.13.35 PM.png] ![Image: Screenshot 2024-08-27 at 3.21.56 PM.png]",
    "sections": [
      {
        "title": "Designing the EVAM’s interior",
        "content": "\nTimeline: January 23, 2023 → April 29, 2024\nClient: Product Design Studio, SUTD, SUTD EVAM Team\nMy Role: 3D designer, Innovator, Prototype designer\nDeliverables: Enhancing the user experience of the EVAM with added lightness.\nTools: 3D printing, Adobe Illustrator, Fusion 360, Generative Design\nDocument: ../Product_Design_Studio.pdf\n\n",
        "level": 1
      },
      {
        "title": "Overview",
        "content": "\n![Image: Untitled]\n\n---\n\n",
        "level": 2
      },
      {
        "title": "**Interior Design for SUTD's EVAM (Electric Vehicle Additive Manufactured)**",
        "content": "\n**Objective:** Design the interior of EVAM, SUTD’s F1-themed electric vehicle, which arrived as a skeleton with no interior design. The goal was to address client concerns and reflect SUTD’s identity.\n\n**Approach:**\n\n- **Client Requirements:** Focused on issues such as ease of entry and exit, designing features like armrests and side compartments for both front and rear seats, and a leg and heel rest for the driver. These features included step platforms and handles to facilitate access for elderly passengers and children.\n- **Design Development:** Over 14 weeks, our team produced a vision render for the EVAM’s interior and developed physical prototypes of the steering wheel, dashboard UI, and screens for both driver and passenger.\n\n**My Deliverables**:\n\n- **Design Solutions:** Addressed key issues by designing practical components to improve vehicle accessibility and comfort.\n- **Prototyping:** Developed physical prototypes of the steering wheel, and passenger and driver screens.\n\n**Learning Outcomes:**\n\n- Emphasised the importance of storyboarding to effectively communicate ideas.\n- Gained experience in hand sketching for initial ideation, producing numerous quick sketches to explore concepts.\n- Created a mood board to establish the design tone, feel, and identity, ensuring uniformity across all components.\n\n",
        "level": 3
      },
      {
        "title": "Design Mood-Board",
        "content": "\n---\n\n![Image: Screenshot 2024-08-27 at 2.56.17 PM.png]\n\n",
        "level": 2
      },
      {
        "title": "Final Design",
        "content": "\n---\n\n![Image: Untitled]\n\n![Image: Untitled]\n\n![Image: Screenshot 2024-08-27 at 3.15.47 PM.png]\n\n![Image: Screenshot 2024-08-27 at 3.16.44 PM.png]\n\n![Image: Screenshot 2024-08-27 at 3.16.59 PM.png]\n\n![Image: Screenshot 2024-08-27 at 3.17.37 PM.png]\n\n",
        "level": 2
      },
      {
        "title": "Physical Prototype",
        "content": "\n---\n\n![Image: Untitled]\n\n![Image: Screenshot 2024-08-27 at 3.19.41 PM.png]\n\n![Image: Screenshot 2024-08-27 at 3.20.08 PM.png]\n\n![Image: Screenshot 2024-08-27 at 3.13.35 PM.png]\n\n![Image: Screenshot 2024-08-27 at 3.21.56 PM.png]\n",
        "level": 2
      }
    ],
    "metadata": {
      "title": "Designing the EVAM’s interior",
      "category": "project",
      "file_name": "Designing the EVAM’s interior 1ac0d79891964c80a91be7094bed7c26",
      "relative_path": "Chin Wei Ming’s Portfolio 28d2a0713ab449fa82d8851c163d4b1f/Projects aee4f34d22394d1690473e4917727405/Designing the EVAM’s interior 1ac0d79891964c80a91be7094bed7c26.md",
      "last_modified": 1749024948.9668968
    },
    "word_count": 312,
    "referenced_files": [
      {
        "name": "Untitled",
        "path": "Designing%20the%20EVAM%E2%80%99s%20interior%201ac0d79891964c80a91be7094bed7c26/Untitled.jpeg",
        "type": "jpeg"
      },
      {
        "name": "Screenshot 2024-08-27 at 2.56.17 PM.png",
        "path": "Designing%20the%20EVAM%E2%80%99s%20interior%201ac0d79891964c80a91be7094bed7c26/Screenshot_2024-08-27_at_2.56.17_PM.png",
        "type": "png"
      },
      {
        "name": "Untitled",
        "path": "Designing%20the%20EVAM%E2%80%99s%20interior%201ac0d79891964c80a91be7094bed7c26/Untitled%201.jpeg",
        "type": "jpeg"
      },
      {
        "name": "Untitled",
        "path": "Designing%20the%20EVAM%E2%80%99s%20interior%201ac0d79891964c80a91be7094bed7c26/Untitled%202.jpeg",
        "type": "jpeg"
      },
      {
        "name": "Screenshot 2024-08-27 at 3.15.47 PM.png",
        "path": "Designing%20the%20EVAM%E2%80%99s%20interior%201ac0d79891964c80a91be7094bed7c26/Screenshot_2024-08-27_at_3.15.47_PM.png",
        "type": "png"
      },
      {
        "name": "Screenshot 2024-08-27 at 3.16.44 PM.png",
        "path": "Designing%20the%20EVAM%E2%80%99s%20interior%201ac0d79891964c80a91be7094bed7c26/Screenshot_2024-08-27_at_3.16.44_PM.png",
        "type": "png"
      },
      {
        "name": "Screenshot 2024-08-27 at 3.16.59 PM.png",
        "path": "Designing%20the%20EVAM%E2%80%99s%20interior%201ac0d79891964c80a91be7094bed7c26/Screenshot_2024-08-27_at_3.16.59_PM.png",
        "type": "png"
      },
      {
        "name": "Screenshot 2024-08-27 at 3.17.37 PM.png",
        "path": "Designing%20the%20EVAM%E2%80%99s%20interior%201ac0d79891964c80a91be7094bed7c26/Screenshot_2024-08-27_at_3.17.37_PM.png",
        "type": "png"
      },
      {
        "name": "Untitled",
        "path": "Designing%20the%20EVAM%E2%80%99s%20interior%201ac0d79891964c80a91be7094bed7c26/Untitled%203.jpeg",
        "type": "jpeg"
      },
      {
        "name": "Screenshot 2024-08-27 at 3.19.41 PM.png",
        "path": "Designing%20the%20EVAM%E2%80%99s%20interior%201ac0d79891964c80a91be7094bed7c26/Screenshot_2024-08-27_at_3.19.41_PM.png",
        "type": "png"
      },
      {
        "name": "Screenshot 2024-08-27 at 3.20.08 PM.png",
        "path": "Designing%20the%20EVAM%E2%80%99s%20interior%201ac0d79891964c80a91be7094bed7c26/Screenshot_2024-08-27_at_3.20.08_PM.png",
        "type": "png"
      },
      {
        "name": "Screenshot 2024-08-27 at 3.13.35 PM.png",
        "path": "Designing%20the%20EVAM%E2%80%99s%20interior%201ac0d79891964c80a91be7094bed7c26/Screenshot_2024-08-27_at_3.13.35_PM.png",
        "type": "png"
      },
      {
        "name": "Screenshot 2024-08-27 at 3.21.56 PM.png",
        "path": "Designing%20the%20EVAM%E2%80%99s%20interior%201ac0d79891964c80a91be7094bed7c26/Screenshot_2024-08-27_at_3.21.56_PM.png",
        "type": "png"
      }
    ]
  },
  {
    "id": "Chin Wei Ming’s Portfolio 28d2a0713ab449fa82d8851c163d4b1f_Projects aee4f34d22394d1690473e4917727405_SUTD Chatbot (LLM + RAG) 1f7f57abcb4e80f0a4d6e36ea3376fcb",
    "source_file": "data/raw/notion_export/Chin Wei Ming’s Portfolio 28d2a0713ab449fa82d8851c163d4b1f/Projects aee4f34d22394d1690473e4917727405/SUTD Chatbot (LLM + RAG) 1f7f57abcb4e80f0a4d6e36ea3376fcb.md",
    "type": "markdown",
    "title": "SUTD Chatbot (LLM + RAG)",
    "category": "project",
    "raw_content": "# SUTD Chatbot (LLM + RAG)\n\nTimeline: February 3, 2025 → April 18, 2025\nClient: SUTD\nMy Role: Machine Learning Engineer\nDeliverables: To develop a chatbot leveraging Retrieval-Augmented Generation (RAG) and Large Language Models (LLMs) to assist prospective students in learning about  Singapore University of Technology and Design (SUTD).\nTools: FAISS (Facebook AI Similarity Search), Llama 3.2 1B model, OpenAI's text-embedding-3-large, Python\nDocument: ../byteus.pdf\nGithub: https://github.com/adikuma/sutd_5055mlop\n\n![byteus.png](SUTD%20Chatbot%20(LLM%20+%20RAG)%201f7f57abcb4e80f0a4d6e36ea3376fcb/byteus.png)\n\n![Screenshot 2025-05-29 at 1.48.08 AM.png](SUTD%20Chatbot%20(LLM%20+%20RAG)%201f7f57abcb4e80f0a4d6e36ea3376fcb/Screenshot_2025-05-29_at_1.48.08_AM.png)\n\n![Screenshot 2025-05-29 at 1.48.20 AM.png](SUTD%20Chatbot%20(LLM%20+%20RAG)%201f7f57abcb4e80f0a4d6e36ea3376fcb/Screenshot_2025-05-29_at_1.48.20_AM.png)\n\n![Screenshot 2025-05-29 at 1.49.01 AM.png](SUTD%20Chatbot%20(LLM%20+%20RAG)%201f7f57abcb4e80f0a4d6e36ea3376fcb/Screenshot_2025-05-29_at_1.49.01_AM.png)",
    "cleaned_content": "# SUTD Chatbot (LLM + RAG)\n\nTimeline: February 3, 2025 → April 18, 2025\nClient: SUTD\nMy Role: Machine Learning Engineer\nDeliverables: To develop a chatbot leveraging Retrieval-Augmented Generation (RAG) and Large Language Models (LLMs) to assist prospective students in learning about Singapore University of Technology and Design (SUTD).\nTools: FAISS (Facebook AI Similarity Search), Llama 3.2 1B model, OpenAI's text-embedding-3-large, Python\nDocument: ../byteus.pdf\nGithub: https://github.com/adikuma/sutd_5055mlop\n\n![byteus.png](SUTD Chatbot (LLM + RAG) 1f7f57abcb4e80f0a4d6e36ea3376fcb/byteus.png)\n\n![Screenshot 2025-05-29 at 1.48.08 AM.png](SUTD Chatbot (LLM + RAG) 1f7f57abcb4e80f0a4d6e36ea3376fcb/Screenshot_2025-05-29_at_1.48.08_AM.png)\n\n![Screenshot 2025-05-29 at 1.48.20 AM.png](SUTD Chatbot (LLM + RAG) 1f7f57abcb4e80f0a4d6e36ea3376fcb/Screenshot_2025-05-29_at_1.48.20_AM.png)\n\n![Screenshot 2025-05-29 at 1.49.01 AM.png](SUTD Chatbot (LLM + RAG) 1f7f57abcb4e80f0a4d6e36ea3376fcb/Screenshot_2025-05-29_at_1.49.01_AM.png)",
    "plain_text": "SUTD Chatbot (LLM + RAG) Timeline: February 3, 2025 → April 18, 2025 Client: SUTD My Role: Machine Learning Engineer Deliverables: To develop a chatbot leveraging Retrieval-Augmented Generation (RAG) and Large Language Models (LLMs) to assist prospective students in learning about Singapore University of Technology and Design (SUTD). Tools: FAISS (Facebook AI Similarity Search), Llama 3.2 1B model, OpenAI's text-embedding-3-large, Python Document: ../byteus.pdf Github: https://github.com/adikuma/sutd_5055mlop",
    "sections": [
      {
        "title": "SUTD Chatbot (LLM + RAG)",
        "content": "\nTimeline: February 3, 2025 → April 18, 2025\nClient: SUTD\nMy Role: Machine Learning Engineer\nDeliverables: To develop a chatbot leveraging Retrieval-Augmented Generation (RAG) and Large Language Models (LLMs) to assist prospective students in learning about Singapore University of Technology and Design (SUTD).\nTools: FAISS (Facebook AI Similarity Search), Llama 3.2 1B model, OpenAI's text-embedding-3-large, Python\nDocument: ../byteus.pdf\nGithub: https://github.com/adikuma/sutd_5055mlop\n\n![byteus.png](SUTD Chatbot (LLM + RAG) 1f7f57abcb4e80f0a4d6e36ea3376fcb/byteus.png)\n\n![Screenshot 2025-05-29 at 1.48.08 AM.png](SUTD Chatbot (LLM + RAG) 1f7f57abcb4e80f0a4d6e36ea3376fcb/Screenshot_2025-05-29_at_1.48.08_AM.png)\n\n![Screenshot 2025-05-29 at 1.48.20 AM.png](SUTD Chatbot (LLM + RAG) 1f7f57abcb4e80f0a4d6e36ea3376fcb/Screenshot_2025-05-29_at_1.48.20_AM.png)\n\n![Screenshot 2025-05-29 at 1.49.01 AM.png](SUTD Chatbot (LLM + RAG) 1f7f57abcb4e80f0a4d6e36ea3376fcb/Screenshot_2025-05-29_at_1.49.01_AM.png)\n",
        "level": 1
      }
    ],
    "metadata": {
      "title": "SUTD Chatbot (LLM + RAG)",
      "category": "project",
      "file_name": "SUTD Chatbot (LLM + RAG) 1f7f57abcb4e80f0a4d6e36ea3376fcb",
      "relative_path": "Chin Wei Ming’s Portfolio 28d2a0713ab449fa82d8851c163d4b1f/Projects aee4f34d22394d1690473e4917727405/SUTD Chatbot (LLM + RAG) 1f7f57abcb4e80f0a4d6e36ea3376fcb.md",
      "last_modified": 1749024949.2857132
    },
    "word_count": 65,
    "referenced_files": []
  },
  {
    "id": "Chin Wei Ming’s Portfolio 28d2a0713ab449fa82d8851c163d4b1f_Projects aee4f34d22394d1690473e4917727405_Sentiment Analysis Design Challenge 19bf57abcb4e80df9ea1f974bfd399b5",
    "source_file": "data/raw/notion_export/Chin Wei Ming’s Portfolio 28d2a0713ab449fa82d8851c163d4b1f/Projects aee4f34d22394d1690473e4917727405/Sentiment Analysis Design Challenge 19bf57abcb4e80df9ea1f974bfd399b5.md",
    "type": "markdown",
    "title": "Sentiment Analysis Design Challenge",
    "category": "project",
    "raw_content": "# Sentiment Analysis Design Challenge\n\nTimeline: September 9, 2024 → December 20, 2024\nClient: 50.040: Natural Language Processing, Prof. Lu Wei\nMy Role: Machine Learning Engineer, NLP Engineer\nDeliverables: Exploration of NLP model architectures., Refinement for improved model performance\nTools: Gensim, Pandas, Python, Pytorch, Transformer (Hugging Face), Vast.ai\nDocument: ../NLP_final_project_report.pdf\n\n![Screenshot 2025-02-15 at 12.19.25 PM.png](Sentiment%20Analysis%20Design%20Challenge%2019bf57abcb4e80df9ea1f974bfd399b5/Screenshot_2025-02-15_at_12.19.25_PM.png)\n\n## Project Overview\n\n---\n\nSentiment analysis is a crucial Natural Language Processing (NLP) task used in various industries, from customer feedback analysis to financial market predictions. This project explores different deep learning architectures to enhance sentiment classification performance on the **IMDB movie reviews dataset**, a widely used benchmark for binary sentiment analysis (positive vs. negative reviews). Our final model, **LoRA-RoBERTa**, achieved the **highest performance**, with an **F1-score of 0.9407** on the test set, demonstrating its ability to accurately capture nuanced sentiment in text. This project highlights the power of **transformer-based models** and **efficient fine-tuning techniques** in advancing sentiment analysis.\n\n## Approach & Methodology\n\n---\n\nTo systematically improve sentiment classification performance, we experimented with various deep learning architectures, progressively enhancing model accuracy and interpretability.\n\n### **Baseline Models: BiRNN & TextCNN**\n\nWe started with **BiRNN (Bidirectional Recurrent Neural Network)** and **TextCNN (Text-based Convolutional Neural Network)** as our baseline models.\n\n- **BiRNN** captured sequential dependencies in text but had limitations in handling long-range dependencies.\n- **TextCNN**, leveraging convolutional layers, excelled at recognizing local n-gram patterns but lacked sequential understanding.\n- Performance Benchmark: **BiRNN achieved 86.48% accuracy, while TextCNN underperformed at 54.94% accuracy**, highlighting the need for further improvements.\n\n### **Ensemble Model: Attention-Based Aggregation**\n\nTo leverage the strengths of both BiRNN and TextCNN, we implemented an **ensemble model** using an **attention-based weighted aggregation mechanism**:\n\n- **Simple Ensemble:** Averaged predictions from BiRNN and TextCNN.\n- **Attention-Based Ensemble:** Assigned dynamic weights to each model’s output based on contextual importance.\n- **Custom Embeddings:** Replaced standard GloVe embeddings with domain-specific Word2Vec embeddings for richer feature representation.\n- **Results:** This approach improved performance, achieving **92.67% accuracy and an F1-score of 0.9273**, but we aimed for further optimization.\n\n### **RoBERTa-BiLSTM: Contextual Embeddings + Sequential Understanding**\n\nTo incorporate **pre-trained language models**, we introduced **RoBERTa** to generate deep contextual embeddings and **BiLSTM (Bidirectional Long Short-Term Memory)** to capture sequential dependencies.\n\n- **RoBERTa provided robust sentence-level representations**, improving sentiment understanding.\n- **BiLSTM processed embeddings bidirectionally**, retaining contextual dependencies across longer text spans.\n- **Results:** This model further improved accuracy to **93.92% with an F1-score of 0.9393**.\n\n### **LoRA-RoBERTa: Efficient Transformer Fine-Tuning (Final Model)**\n\nGiven computational constraints, we fine-tuned **RoBERTa-large** using **Low-Rank Adaptation (LoRA)**, a parameter-efficient tuning method.\n\n- **Why LoRA?** Instead of updating all 355M parameters in RoBERTa-large, LoRA fine-tuned only a subset of trainable parameters, significantly reducing memory requirements while maintaining high performance.\n- **Optimization Techniques:** Used **AdamW optimizer, gradient clipping, and linear learning rate scheduling** for stable training.\n- **Final Results:** **LoRA-RoBERTa achieved the best performance with an F1-score of 0.9407**, outperforming all previous models.\n\n## Results\n\n---\n\nThrough systematic experimentation, we observed consistent improvements in sentiment classification performance as we transitioned from traditional deep learning models to **transformer-based architectures**.\n\n| Model | Accuracy | Precision | Recall | F1 score |\n| --- | --- | --- | --- | --- |\n| **BiRNN (Baseline)** | 86.48% | 83.85% | 90.34% | 86.97% |\n| **TextCNN (Baseline)** | 54.94% | 52.61% | 98.88% | 68.67% |\n| **Ensemble Model** | 92.67% | 91.90% | 93.58% | 92.73% |\n| **RoBERTa-BiLSTM** | 93.92% | 93.68% | 94.18% | 93.93% |\n| **LoRA-RoBERTa** | 94.08% | 94.25% | 93.88% | 94.07% |\n\n📌 **Key Takeaways:**\n\n- **BiRNN performed well but struggled with long-range dependencies.**\n- **TextCNN underperformed due to its lack of sequential context.**\n- **The Ensemble model improved performance** by combining both architectures with attention-based weighting.\n- **RoBERTa-BiLSTM outperformed the ensemble model** by leveraging contextual embeddings with sequential processing.\n- **LoRA-RoBERTa achieved the best results, demonstrating the effectiveness of transformer-based fine-tuning.**\n\n## Challenges\n\n---\n\n🔹 **Computational Constraints:**\n\n- **Challenge:** Training **RoBERTa-large** was computationally expensive.\n- **Solution:** Used **Low-Rank Adaptation (LoRA)** to fine-tune only a subset of parameters, reducing memory usage while maintaining high performance.\n\n🔹 **Dataset Preprocessing Issues:**\n\n- **Challenge:** The IMDB dataset required extensive text cleaning and handling of imbalanced classes.\n- **Solution:** Implemented **NLTK-based preprocessing** (lemmatization, stopword removal) and **balanced batches** using PyTorch DataLoader.\n\n🔹 **Hyperparameter Optimization:**\n\n- **Challenge:** Finding the best learning rate, batch size, and hidden dimensions was time-intensive.\n- **Solution:** Used **Grid Search** to optimize hyperparameters efficiently.",
    "cleaned_content": "# Sentiment Analysis Design Challenge\n\nTimeline: September 9, 2024 → December 20, 2024\nClient: 50.040: Natural Language Processing, Prof. Lu Wei\nMy Role: Machine Learning Engineer, NLP Engineer\nDeliverables: Exploration of NLP model architectures., Refinement for improved model performance\nTools: Gensim, Pandas, Python, Pytorch, Transformer (Hugging Face), Vast.ai\nDocument: ../NLP_final_project_report.pdf\n\n![Image: Screenshot 2025-02-15 at 12.19.25 PM.png]\n\n## Project Overview\n\n---\n\nSentiment analysis is a crucial Natural Language Processing (NLP) task used in various industries, from customer feedback analysis to financial market predictions. This project explores different deep learning architectures to enhance sentiment classification performance on the **IMDB movie reviews dataset**, a widely used benchmark for binary sentiment analysis (positive vs. negative reviews). Our final model, **LoRA-RoBERTa**, achieved the **highest performance**, with an **F1-score of 0.9407** on the test set, demonstrating its ability to accurately capture nuanced sentiment in text. This project highlights the power of **transformer-based models** and **efficient fine-tuning techniques** in advancing sentiment analysis.\n\n## Approach & Methodology\n\n---\n\nTo systematically improve sentiment classification performance, we experimented with various deep learning architectures, progressively enhancing model accuracy and interpretability.\n\n### **Baseline Models: BiRNN & TextCNN**\n\nWe started with **BiRNN (Bidirectional Recurrent Neural Network)** and **TextCNN (Text-based Convolutional Neural Network)** as our baseline models.\n\n- **BiRNN** captured sequential dependencies in text but had limitations in handling long-range dependencies.\n- **TextCNN**, leveraging convolutional layers, excelled at recognizing local n-gram patterns but lacked sequential understanding.\n- Performance Benchmark: **BiRNN achieved 86.48% accuracy, while TextCNN underperformed at 54.94% accuracy**, highlighting the need for further improvements.\n\n### **Ensemble Model: Attention-Based Aggregation**\n\nTo leverage the strengths of both BiRNN and TextCNN, we implemented an **ensemble model** using an **attention-based weighted aggregation mechanism**:\n\n- **Simple Ensemble:** Averaged predictions from BiRNN and TextCNN.\n- **Attention-Based Ensemble:** Assigned dynamic weights to each model’s output based on contextual importance.\n- **Custom Embeddings:** Replaced standard GloVe embeddings with domain-specific Word2Vec embeddings for richer feature representation.\n- **Results:** This approach improved performance, achieving **92.67% accuracy and an F1-score of 0.9273**, but we aimed for further optimization.\n\n### **RoBERTa-BiLSTM: Contextual Embeddings + Sequential Understanding**\n\nTo incorporate **pre-trained language models**, we introduced **RoBERTa** to generate deep contextual embeddings and **BiLSTM (Bidirectional Long Short-Term Memory)** to capture sequential dependencies.\n\n- **RoBERTa provided robust sentence-level representations**, improving sentiment understanding.\n- **BiLSTM processed embeddings bidirectionally**, retaining contextual dependencies across longer text spans.\n- **Results:** This model further improved accuracy to **93.92% with an F1-score of 0.9393**.\n\n### **LoRA-RoBERTa: Efficient Transformer Fine-Tuning (Final Model)**\n\nGiven computational constraints, we fine-tuned **RoBERTa-large** using **Low-Rank Adaptation (LoRA)**, a parameter-efficient tuning method.\n\n- **Why LoRA?** Instead of updating all 355M parameters in RoBERTa-large, LoRA fine-tuned only a subset of trainable parameters, significantly reducing memory requirements while maintaining high performance.\n- **Optimization Techniques:** Used **AdamW optimizer, gradient clipping, and linear learning rate scheduling** for stable training.\n- **Final Results:** **LoRA-RoBERTa achieved the best performance with an F1-score of 0.9407**, outperforming all previous models.\n\n## Results\n\n---\n\nThrough systematic experimentation, we observed consistent improvements in sentiment classification performance as we transitioned from traditional deep learning models to **transformer-based architectures**.\n\n| Model | Accuracy | Precision | Recall | F1 score |\n| --- | --- | --- | --- | --- |\n| **BiRNN (Baseline)** | 86.48% | 83.85% | 90.34% | 86.97% |\n| **TextCNN (Baseline)** | 54.94% | 52.61% | 98.88% | 68.67% |\n| **Ensemble Model** | 92.67% | 91.90% | 93.58% | 92.73% |\n| **RoBERTa-BiLSTM** | 93.92% | 93.68% | 94.18% | 93.93% |\n| **LoRA-RoBERTa** | 94.08% | 94.25% | 93.88% | 94.07% |\n\n📌 **Key Takeaways:**\n\n- **BiRNN performed well but struggled with long-range dependencies.**\n- **TextCNN underperformed due to its lack of sequential context.**\n- **The Ensemble model improved performance** by combining both architectures with attention-based weighting.\n- **RoBERTa-BiLSTM outperformed the ensemble model** by leveraging contextual embeddings with sequential processing.\n- **LoRA-RoBERTa achieved the best results, demonstrating the effectiveness of transformer-based fine-tuning.**\n\n## Challenges\n\n---\n\n🔹 **Computational Constraints:**\n\n- **Challenge:** Training **RoBERTa-large** was computationally expensive.\n- **Solution:** Used **Low-Rank Adaptation (LoRA)** to fine-tune only a subset of parameters, reducing memory usage while maintaining high performance.\n\n🔹 **Dataset Preprocessing Issues:**\n\n- **Challenge:** The IMDB dataset required extensive text cleaning and handling of imbalanced classes.\n- **Solution:** Implemented **NLTK-based preprocessing** (lemmatization, stopword removal) and **balanced batches** using PyTorch DataLoader.\n\n🔹 **Hyperparameter Optimization:**\n\n- **Challenge:** Finding the best learning rate, batch size, and hidden dimensions was time-intensive.\n- **Solution:** Used **Grid Search** to optimize hyperparameters efficiently.",
    "plain_text": "Sentiment Analysis Design Challenge Timeline: September 9, 2024 → December 20, 2024 Client: 50.040: Natural Language Processing, Prof. Lu Wei My Role: Machine Learning Engineer, NLP Engineer Deliverables: Exploration of NLP model architectures., Refinement for improved model performance Tools: Gensim, Pandas, Python, Pytorch, Transformer (Hugging Face), Vast.ai Document: ../NLP_final_project_report.pdf ![Image: Screenshot 2025-02-15 at 12.19.25 PM.png] Project Overview Sentiment analysis is a crucial Natural Language Processing (NLP) task used in various industries, from customer feedback analysis to financial market predictions. This project explores different deep learning architectures to enhance sentiment classification performance on the IMDB movie reviews dataset, a widely used benchmark for binary sentiment analysis (positive vs. negative reviews). Our final model, LoRA-RoBERTa, achieved the highest performance, with an F1-score of 0.9407 on the test set, demonstrating its ability to accurately capture nuanced sentiment in text. This project highlights the power of transformer-based models and efficient fine-tuning techniques in advancing sentiment analysis. Approach & Methodology To systematically improve sentiment classification performance, we experimented with various deep learning architectures, progressively enhancing model accuracy and interpretability. Baseline Models: BiRNN & TextCNN We started with BiRNN (Bidirectional Recurrent Neural Network) and TextCNN (Text-based Convolutional Neural Network) as our baseline models. BiRNN captured sequential dependencies in text but had limitations in handling long-range dependencies. TextCNN, leveraging convolutional layers, excelled at recognizing local n-gram patterns but lacked sequential understanding. Performance Benchmark: BiRNN achieved 86.48% accuracy, while TextCNN underperformed at 54.94% accuracy, highlighting the need for further improvements. Ensemble Model: Attention-Based Aggregation To leverage the strengths of both BiRNN and TextCNN, we implemented an ensemble model using an attention-based weighted aggregation mechanism: Simple Ensemble: Averaged predictions from BiRNN and TextCNN. Attention-Based Ensemble: Assigned dynamic weights to each model’s output based on contextual importance. Custom Embeddings: Replaced standard GloVe embeddings with domain-specific Word2Vec embeddings for richer feature representation. Results: This approach improved performance, achieving 92.67% accuracy and an F1-score of 0.9273, but we aimed for further optimization. RoBERTa-BiLSTM: Contextual Embeddings + Sequential Understanding To incorporate pre-trained language models, we introduced RoBERTa to generate deep contextual embeddings and BiLSTM (Bidirectional Long Short-Term Memory) to capture sequential dependencies. RoBERTa provided robust sentence-level representations, improving sentiment understanding. BiLSTM processed embeddings bidirectionally, retaining contextual dependencies across longer text spans. Results: This model further improved accuracy to 93.92% with an F1-score of 0.9393. LoRA-RoBERTa: Efficient Transformer Fine-Tuning (Final Model) Given computational constraints, we fine-tuned RoBERTa-large using Low-Rank Adaptation (LoRA), a parameter-efficient tuning method. Why LoRA? Instead of updating all 355M parameters in RoBERTa-large, LoRA fine-tuned only a subset of trainable parameters, significantly reducing memory requirements while maintaining high performance. Optimization Techniques: Used AdamW optimizer, gradient clipping, and linear learning rate scheduling for stable training. Final Results: LoRA-RoBERTa achieved the best performance with an F1-score of 0.9407, outperforming all previous models. Results Through systematic experimentation, we observed consistent improvements in sentiment classification performance as we transitioned from traditional deep learning models to transformer-based architectures. Model Accuracy Precision Recall F1 score BiRNN (Baseline) 86.48% 83.85% 90.34% 86.97% TextCNN (Baseline) 54.94% 52.61% 98.88% 68.67% Ensemble Model 92.67% 91.90% 93.58% 92.73% RoBERTa-BiLSTM 93.92% 93.68% 94.18% 93.93% LoRA-RoBERTa 94.08% 94.25% 93.88% 94.07% 📌 Key Takeaways: BiRNN performed well but struggled with long-range dependencies. TextCNN underperformed due to its lack of sequential context. The Ensemble model improved performance by combining both architectures with attention-based weighting. RoBERTa-BiLSTM outperformed the ensemble model by leveraging contextual embeddings with sequential processing. LoRA-RoBERTa achieved the best results, demonstrating the effectiveness of transformer-based fine-tuning. Challenges 🔹 Computational Constraints: Challenge: Training RoBERTa-large was computationally expensive. Solution: Used Low-Rank Adaptation (LoRA) to fine-tune only a subset of parameters, reducing memory usage while maintaining high performance. 🔹 Dataset Preprocessing Issues: Challenge: The IMDB dataset required extensive text cleaning and handling of imbalanced classes. Solution: Implemented NLTK-based preprocessing (lemmatization, stopword removal) and balanced batches using PyTorch DataLoader. 🔹 Hyperparameter Optimization: Challenge: Finding the best learning rate, batch size, and hidden dimensions was time-intensive. Solution: Used Grid Search to optimize hyperparameters efficiently.",
    "sections": [
      {
        "title": "Sentiment Analysis Design Challenge",
        "content": "\nTimeline: September 9, 2024 → December 20, 2024\nClient: 50.040: Natural Language Processing, Prof. Lu Wei\nMy Role: Machine Learning Engineer, NLP Engineer\nDeliverables: Exploration of NLP model architectures., Refinement for improved model performance\nTools: Gensim, Pandas, Python, Pytorch, Transformer (Hugging Face), Vast.ai\nDocument: ../NLP_final_project_report.pdf\n\n![Image: Screenshot 2025-02-15 at 12.19.25 PM.png]\n\n",
        "level": 1
      },
      {
        "title": "Project Overview",
        "content": "\n---\n\nSentiment analysis is a crucial Natural Language Processing (NLP) task used in various industries, from customer feedback analysis to financial market predictions. This project explores different deep learning architectures to enhance sentiment classification performance on the **IMDB movie reviews dataset**, a widely used benchmark for binary sentiment analysis (positive vs. negative reviews). Our final model, **LoRA-RoBERTa**, achieved the **highest performance**, with an **F1-score of 0.9407** on the test set, demonstrating its ability to accurately capture nuanced sentiment in text. This project highlights the power of **transformer-based models** and **efficient fine-tuning techniques** in advancing sentiment analysis.\n\n",
        "level": 2
      },
      {
        "title": "Approach & Methodology",
        "content": "\n---\n\nTo systematically improve sentiment classification performance, we experimented with various deep learning architectures, progressively enhancing model accuracy and interpretability.\n\n",
        "level": 2
      },
      {
        "title": "**Baseline Models: BiRNN & TextCNN**",
        "content": "\nWe started with **BiRNN (Bidirectional Recurrent Neural Network)** and **TextCNN (Text-based Convolutional Neural Network)** as our baseline models.\n\n- **BiRNN** captured sequential dependencies in text but had limitations in handling long-range dependencies.\n- **TextCNN**, leveraging convolutional layers, excelled at recognizing local n-gram patterns but lacked sequential understanding.\n- Performance Benchmark: **BiRNN achieved 86.48% accuracy, while TextCNN underperformed at 54.94% accuracy**, highlighting the need for further improvements.\n\n",
        "level": 3
      },
      {
        "title": "**Ensemble Model: Attention-Based Aggregation**",
        "content": "\nTo leverage the strengths of both BiRNN and TextCNN, we implemented an **ensemble model** using an **attention-based weighted aggregation mechanism**:\n\n- **Simple Ensemble:** Averaged predictions from BiRNN and TextCNN.\n- **Attention-Based Ensemble:** Assigned dynamic weights to each model’s output based on contextual importance.\n- **Custom Embeddings:** Replaced standard GloVe embeddings with domain-specific Word2Vec embeddings for richer feature representation.\n- **Results:** This approach improved performance, achieving **92.67% accuracy and an F1-score of 0.9273**, but we aimed for further optimization.\n\n",
        "level": 3
      },
      {
        "title": "**RoBERTa-BiLSTM: Contextual Embeddings + Sequential Understanding**",
        "content": "\nTo incorporate **pre-trained language models**, we introduced **RoBERTa** to generate deep contextual embeddings and **BiLSTM (Bidirectional Long Short-Term Memory)** to capture sequential dependencies.\n\n- **RoBERTa provided robust sentence-level representations**, improving sentiment understanding.\n- **BiLSTM processed embeddings bidirectionally**, retaining contextual dependencies across longer text spans.\n- **Results:** This model further improved accuracy to **93.92% with an F1-score of 0.9393**.\n\n",
        "level": 3
      },
      {
        "title": "**LoRA-RoBERTa: Efficient Transformer Fine-Tuning (Final Model)**",
        "content": "\nGiven computational constraints, we fine-tuned **RoBERTa-large** using **Low-Rank Adaptation (LoRA)**, a parameter-efficient tuning method.\n\n- **Why LoRA?** Instead of updating all 355M parameters in RoBERTa-large, LoRA fine-tuned only a subset of trainable parameters, significantly reducing memory requirements while maintaining high performance.\n- **Optimization Techniques:** Used **AdamW optimizer, gradient clipping, and linear learning rate scheduling** for stable training.\n- **Final Results:** **LoRA-RoBERTa achieved the best performance with an F1-score of 0.9407**, outperforming all previous models.\n\n",
        "level": 3
      },
      {
        "title": "Results",
        "content": "\n---\n\nThrough systematic experimentation, we observed consistent improvements in sentiment classification performance as we transitioned from traditional deep learning models to **transformer-based architectures**.\n\n| Model | Accuracy | Precision | Recall | F1 score |\n| --- | --- | --- | --- | --- |\n| **BiRNN (Baseline)** | 86.48% | 83.85% | 90.34% | 86.97% |\n| **TextCNN (Baseline)** | 54.94% | 52.61% | 98.88% | 68.67% |\n| **Ensemble Model** | 92.67% | 91.90% | 93.58% | 92.73% |\n| **RoBERTa-BiLSTM** | 93.92% | 93.68% | 94.18% | 93.93% |\n| **LoRA-RoBERTa** | 94.08% | 94.25% | 93.88% | 94.07% |\n\n📌 **Key Takeaways:**\n\n- **BiRNN performed well but struggled with long-range dependencies.**\n- **TextCNN underperformed due to its lack of sequential context.**\n- **The Ensemble model improved performance** by combining both architectures with attention-based weighting.\n- **RoBERTa-BiLSTM outperformed the ensemble model** by leveraging contextual embeddings with sequential processing.\n- **LoRA-RoBERTa achieved the best results, demonstrating the effectiveness of transformer-based fine-tuning.**\n\n",
        "level": 2
      },
      {
        "title": "Challenges",
        "content": "\n---\n\n🔹 **Computational Constraints:**\n\n- **Challenge:** Training **RoBERTa-large** was computationally expensive.\n- **Solution:** Used **Low-Rank Adaptation (LoRA)** to fine-tune only a subset of parameters, reducing memory usage while maintaining high performance.\n\n🔹 **Dataset Preprocessing Issues:**\n\n- **Challenge:** The IMDB dataset required extensive text cleaning and handling of imbalanced classes.\n- **Solution:** Implemented **NLTK-based preprocessing** (lemmatization, stopword removal) and **balanced batches** using PyTorch DataLoader.\n\n🔹 **Hyperparameter Optimization:**\n\n- **Challenge:** Finding the best learning rate, batch size, and hidden dimensions was time-intensive.\n- **Solution:** Used **Grid Search** to optimize hyperparameters efficiently.\n",
        "level": 2
      }
    ],
    "metadata": {
      "title": "Sentiment Analysis Design Challenge",
      "category": "project",
      "file_name": "Sentiment Analysis Design Challenge 19bf57abcb4e80df9ea1f974bfd399b5",
      "relative_path": "Chin Wei Ming’s Portfolio 28d2a0713ab449fa82d8851c163d4b1f/Projects aee4f34d22394d1690473e4917727405/Sentiment Analysis Design Challenge 19bf57abcb4e80df9ea1f974bfd399b5.md",
      "last_modified": 1749024949.2899663
    },
    "word_count": 653,
    "referenced_files": [
      {
        "name": "Screenshot 2025-02-15 at 12.19.25 PM.png",
        "path": "Sentiment%20Analysis%20Design%20Challenge%2019bf57abcb4e80df9ea1f974bfd399b5/Screenshot_2025-02-15_at_12.19.25_PM.png",
        "type": "png"
      }
    ]
  },
  {
    "id": "Chin Wei Ming’s Portfolio 28d2a0713ab449fa82d8851c163d4b1f_Projects aee4f34d22394d1690473e4917727405_Untitled 3a6b82bd21fd4beb89f33d5eccd18f33",
    "source_file": "data/raw/notion_export/Chin Wei Ming’s Portfolio 28d2a0713ab449fa82d8851c163d4b1f/Projects aee4f34d22394d1690473e4917727405/Untitled 3a6b82bd21fd4beb89f33d5eccd18f33.md",
    "type": "markdown",
    "title": "Untitled",
    "category": "project",
    "raw_content": "# Untitled",
    "cleaned_content": "# Untitled",
    "plain_text": "Untitled",
    "sections": [],
    "metadata": {
      "title": "Untitled",
      "category": "project",
      "file_name": "Untitled 3a6b82bd21fd4beb89f33d5eccd18f33",
      "relative_path": "Chin Wei Ming’s Portfolio 28d2a0713ab449fa82d8851c163d4b1f/Projects aee4f34d22394d1690473e4917727405/Untitled 3a6b82bd21fd4beb89f33d5eccd18f33.md",
      "last_modified": 1749024949.4718225
    },
    "word_count": 1,
    "referenced_files": []
  },
  {
    "id": "Chin Wei Ming’s Portfolio 28d2a0713ab449fa82d8851c163d4b1f_Projects aee4f34d22394d1690473e4917727405_Re-thinking Expo MRT 9a38f07ad6a64023972871810c123c35",
    "source_file": "data/raw/notion_export/Chin Wei Ming’s Portfolio 28d2a0713ab449fa82d8851c163d4b1f/Projects aee4f34d22394d1690473e4917727405/Re-thinking Expo MRT 9a38f07ad6a64023972871810c123c35.md",
    "type": "markdown",
    "title": "Re-thinking Expo MRT",
    "category": "project",
    "raw_content": "# Re-thinking Expo MRT\n\nTimeline: August 28, 2022 → April 28, 2024\nClient: SUTD\nMy Role: 3D designer, Innovator, Prototype designer\nDeliverables: Improve human flow efficiency in Expo MRT\nTools: Adobe Illustrator, Fusion 360\n\n## Overview\n\n![photo_2022-04-22-20.48.06.jpeg](Re-thinking%20Expo%20MRT%209a38f07ad6a64023972871810c123c35/photo_2022-04-22-20.48.06.jpeg)\n\n---\n\nThe Expo MRT station, built over 20 years ago, no longer meets the needs of modern commuters, especially during peak hours. Our team reimagined the station's layout from an architectural perspective to enhance movement efficiency. We focused on optimising human traffic flow during peak periods.\n\nI led the 3D modelling process, using Fusion 360 to bring our team's ideas to life. This involved multiple iterations to refine the design and address potential flaws. Once finalised, I developed the physical prototype. While our design may not be implemented, it serves as a valuable reference for future train station designs globally.\n\n## Problem\n\n---\n\n![Screenshot 2023-04-04 at 11.38.08 AM.png](Re-thinking%20Expo%20MRT%209a38f07ad6a64023972871810c123c35/Screenshot_2023-04-04_at_11.38.08_AM.png)\n\n- Overcrowding and congestion during peak hours.\n- Commuters colliding into one and another, was not ideal during Covid-19 period.\n\n## Solutions\n\n- **Split Platform**\n    \n    ![Screenshot 2023-04-04 at 11.42.10 AM.png](Re-thinking%20Expo%20MRT%209a38f07ad6a64023972871810c123c35/Screenshot_2023-04-04_at_11.42.10_AM.png)\n    \n\n- **Elliptical Shape**\n    \n    ![Screenshot 2023-04-04 at 11.41.32 AM.png](Re-thinking%20Expo%20MRT%209a38f07ad6a64023972871810c123c35/Screenshot_2023-04-04_at_11.41.32_AM.png)\n    \n\n- Floor plan (gantry level)\n    \n    ![Screenshot 2023-04-04 at 11.45.31 AM.png](Re-thinking%20Expo%20MRT%209a38f07ad6a64023972871810c123c35/Screenshot_2023-04-04_at_11.45.31_AM.png)\n    \n\n- Floor plan (platform level)\n    \n    ![Screenshot 2023-04-04 at 11.44.45 AM.png](Re-thinking%20Expo%20MRT%209a38f07ad6a64023972871810c123c35/Screenshot_2023-04-04_at_11.44.45_AM.png)\n    \n- **Systematic Dispersion With Train Door Sequence**\n    \n    ![Screenshot 2023-04-04 at 11.42.43 AM.png](Re-thinking%20Expo%20MRT%209a38f07ad6a64023972871810c123c35/Screenshot_2023-04-04_at_11.42.43_AM.png)\n    \n\n## Results\n\n---\n\n### 66%\n\nimprovement in efficiency of passenger’s movement during peak commuting hours.\n\n### 66.7%\n\nusers agree that we have effectively dealt with our problem statement.\n\n## Final Product\n\n![xphoto_2022-04-21_02-58-35-1.jpg.pagespeed.ic.BKMBZvBK4b.jpg](Re-thinking%20Expo%20MRT%209a38f07ad6a64023972871810c123c35/xphoto_2022-04-21_02-58-35-1.jpg.pagespeed.ic.BKMBZvBK4b.jpg)\n\n---\n\n![photo_2022-04-22-09.53.34.jpeg](Re-thinking%20Expo%20MRT%209a38f07ad6a64023972871810c123c35/photo_2022-04-22-09.53.34.jpeg)\n\n---\n\n---",
    "cleaned_content": "# Re-thinking Expo MRT\n\nTimeline: August 28, 2022 → April 28, 2024\nClient: SUTD\nMy Role: 3D designer, Innovator, Prototype designer\nDeliverables: Improve human flow efficiency in Expo MRT\nTools: Adobe Illustrator, Fusion 360\n\n## Overview\n\n![Image: photo_2022-04-22-20.48.06.jpeg]\n\n---\n\nThe Expo MRT station, built over 20 years ago, no longer meets the needs of modern commuters, especially during peak hours. Our team reimagined the station's layout from an architectural perspective to enhance movement efficiency. We focused on optimising human traffic flow during peak periods.\n\nI led the 3D modelling process, using Fusion 360 to bring our team's ideas to life. This involved multiple iterations to refine the design and address potential flaws. Once finalised, I developed the physical prototype. While our design may not be implemented, it serves as a valuable reference for future train station designs globally.\n\n## Problem\n\n---\n\n![Image: Screenshot 2023-04-04 at 11.38.08 AM.png]\n\n- Overcrowding and congestion during peak hours.\n- Commuters colliding into one and another, was not ideal during Covid-19 period.\n\n## Solutions\n\n- **Split Platform**\n \n ![Image: Screenshot 2023-04-04 at 11.42.10 AM.png]\n\n- **Elliptical Shape**\n \n ![Image: Screenshot 2023-04-04 at 11.41.32 AM.png]\n\n- Floor plan (gantry level)\n \n ![Image: Screenshot 2023-04-04 at 11.45.31 AM.png]\n\n- Floor plan (platform level)\n \n ![Image: Screenshot 2023-04-04 at 11.44.45 AM.png]\n \n- **Systematic Dispersion With Train Door Sequence**\n \n ![Image: Screenshot 2023-04-04 at 11.42.43 AM.png]\n\n## Results\n\n---\n\n### 66%\n\nimprovement in efficiency of passenger’s movement during peak commuting hours.\n\n### 66.7%\n\nusers agree that we have effectively dealt with our problem statement.\n\n## Final Product\n\n![Image: xphoto_2022-04-21_02-58-35-1.jpg.pagespeed.ic.BKMBZvBK4b.jpg]\n\n---\n\n![Image: photo_2022-04-22-09.53.34.jpeg]\n\n---\n\n---",
    "plain_text": "Re-thinking Expo MRT Timeline: August 28, 2022 → April 28, 2024 Client: SUTD My Role: 3D designer, Innovator, Prototype designer Deliverables: Improve human flow efficiency in Expo MRT Tools: Adobe Illustrator, Fusion 360 Overview ![Image: photo_2022-04-22-20.48.06.jpeg] The Expo MRT station, built over 20 years ago, no longer meets the needs of modern commuters, especially during peak hours. Our team reimagined the station's layout from an architectural perspective to enhance movement efficiency. We focused on optimising human traffic flow during peak periods. I led the 3D modelling process, using Fusion 360 to bring our team's ideas to life. This involved multiple iterations to refine the design and address potential flaws. Once finalised, I developed the physical prototype. While our design may not be implemented, it serves as a valuable reference for future train station designs globally. Problem ![Image: Screenshot 2023-04-04 at 11.38.08 AM.png] Overcrowding and congestion during peak hours. Commuters colliding into one and another, was not ideal during Covid-19 period. Solutions Split Platform ![Image: Screenshot 2023-04-04 at 11.42.10 AM.png] Elliptical Shape ![Image: Screenshot 2023-04-04 at 11.41.32 AM.png] Floor plan (gantry level) ![Image: Screenshot 2023-04-04 at 11.45.31 AM.png] Floor plan (platform level) ![Image: Screenshot 2023-04-04 at 11.44.45 AM.png] Systematic Dispersion With Train Door Sequence ![Image: Screenshot 2023-04-04 at 11.42.43 AM.png] Results 66% improvement in efficiency of passenger’s movement during peak commuting hours. 66.7% users agree that we have effectively dealt with our problem statement. Final Product ![Image: xphoto_2022-04-21_02-58-35-1.jpg.pagespeed.ic.BKMBZvBK4b.jpg] ![Image: photo_2022-04-22-09.53.34.jpeg]",
    "sections": [
      {
        "title": "Re-thinking Expo MRT",
        "content": "\nTimeline: August 28, 2022 → April 28, 2024\nClient: SUTD\nMy Role: 3D designer, Innovator, Prototype designer\nDeliverables: Improve human flow efficiency in Expo MRT\nTools: Adobe Illustrator, Fusion 360\n\n",
        "level": 1
      },
      {
        "title": "Overview",
        "content": "\n![Image: photo_2022-04-22-20.48.06.jpeg]\n\n---\n\nThe Expo MRT station, built over 20 years ago, no longer meets the needs of modern commuters, especially during peak hours. Our team reimagined the station's layout from an architectural perspective to enhance movement efficiency. We focused on optimising human traffic flow during peak periods.\n\nI led the 3D modelling process, using Fusion 360 to bring our team's ideas to life. This involved multiple iterations to refine the design and address potential flaws. Once finalised, I developed the physical prototype. While our design may not be implemented, it serves as a valuable reference for future train station designs globally.\n\n",
        "level": 2
      },
      {
        "title": "Problem",
        "content": "\n---\n\n![Image: Screenshot 2023-04-04 at 11.38.08 AM.png]\n\n- Overcrowding and congestion during peak hours.\n- Commuters colliding into one and another, was not ideal during Covid-19 period.\n\n",
        "level": 2
      },
      {
        "title": "Solutions",
        "content": "\n- **Split Platform**\n \n ![Image: Screenshot 2023-04-04 at 11.42.10 AM.png]\n\n- **Elliptical Shape**\n \n ![Image: Screenshot 2023-04-04 at 11.41.32 AM.png]\n\n- Floor plan (gantry level)\n \n ![Image: Screenshot 2023-04-04 at 11.45.31 AM.png]\n\n- Floor plan (platform level)\n \n ![Image: Screenshot 2023-04-04 at 11.44.45 AM.png]\n \n- **Systematic Dispersion With Train Door Sequence**\n \n ![Image: Screenshot 2023-04-04 at 11.42.43 AM.png]\n\n",
        "level": 2
      },
      {
        "title": "Results",
        "content": "\n---\n\n",
        "level": 2
      },
      {
        "title": "66%",
        "content": "\nimprovement in efficiency of passenger’s movement during peak commuting hours.\n\n",
        "level": 3
      },
      {
        "title": "66.7%",
        "content": "\nusers agree that we have effectively dealt with our problem statement.\n\n",
        "level": 3
      },
      {
        "title": "Final Product",
        "content": "\n![Image: xphoto_2022-04-21_02-58-35-1.jpg.pagespeed.ic.BKMBZvBK4b.jpg]\n\n---\n\n![Image: photo_2022-04-22-09.53.34.jpeg]\n\n---\n\n---\n",
        "level": 2
      }
    ],
    "metadata": {
      "title": "Re-thinking Expo MRT",
      "category": "project",
      "file_name": "Re-thinking Expo MRT 9a38f07ad6a64023972871810c123c35",
      "relative_path": "Chin Wei Ming’s Portfolio 28d2a0713ab449fa82d8851c163d4b1f/Projects aee4f34d22394d1690473e4917727405/Re-thinking Expo MRT 9a38f07ad6a64023972871810c123c35.md",
      "last_modified": 1749024949.078144
    },
    "word_count": 239,
    "referenced_files": [
      {
        "name": "photo_2022-04-22-20.48.06.jpeg",
        "path": "Re-thinking%20Expo%20MRT%209a38f07ad6a64023972871810c123c35/photo_2022-04-22-20.48.06.jpeg",
        "type": "jpeg"
      },
      {
        "name": "Screenshot 2023-04-04 at 11.38.08 AM.png",
        "path": "Re-thinking%20Expo%20MRT%209a38f07ad6a64023972871810c123c35/Screenshot_2023-04-04_at_11.38.08_AM.png",
        "type": "png"
      },
      {
        "name": "Screenshot 2023-04-04 at 11.42.10 AM.png",
        "path": "Re-thinking%20Expo%20MRT%209a38f07ad6a64023972871810c123c35/Screenshot_2023-04-04_at_11.42.10_AM.png",
        "type": "png"
      },
      {
        "name": "Screenshot 2023-04-04 at 11.41.32 AM.png",
        "path": "Re-thinking%20Expo%20MRT%209a38f07ad6a64023972871810c123c35/Screenshot_2023-04-04_at_11.41.32_AM.png",
        "type": "png"
      },
      {
        "name": "Screenshot 2023-04-04 at 11.45.31 AM.png",
        "path": "Re-thinking%20Expo%20MRT%209a38f07ad6a64023972871810c123c35/Screenshot_2023-04-04_at_11.45.31_AM.png",
        "type": "png"
      },
      {
        "name": "Screenshot 2023-04-04 at 11.44.45 AM.png",
        "path": "Re-thinking%20Expo%20MRT%209a38f07ad6a64023972871810c123c35/Screenshot_2023-04-04_at_11.44.45_AM.png",
        "type": "png"
      },
      {
        "name": "Screenshot 2023-04-04 at 11.42.43 AM.png",
        "path": "Re-thinking%20Expo%20MRT%209a38f07ad6a64023972871810c123c35/Screenshot_2023-04-04_at_11.42.43_AM.png",
        "type": "png"
      },
      {
        "name": "xphoto_2022-04-21_02-58-35-1.jpg.pagespeed.ic.BKMBZvBK4b.jpg",
        "path": "Re-thinking%20Expo%20MRT%209a38f07ad6a64023972871810c123c35/xphoto_2022-04-21_02-58-35-1.jpg.pagespeed.ic.BKMBZvBK4b.jpg",
        "type": "jpg"
      },
      {
        "name": "photo_2022-04-22-09.53.34.jpeg",
        "path": "Re-thinking%20Expo%20MRT%209a38f07ad6a64023972871810c123c35/photo_2022-04-22-09.53.34.jpeg",
        "type": "jpeg"
      }
    ]
  }
]